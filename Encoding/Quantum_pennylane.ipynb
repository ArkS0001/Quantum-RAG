{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8f956d88e3843f592f6092348e8f833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8b13715adab4572bdd3226a1476b317",
              "IPY_MODEL_539bc31905b8444e97e50ded4da26868",
              "IPY_MODEL_8a43a2fcb8a9492eaea0cb472816e8db"
            ],
            "layout": "IPY_MODEL_41ed5295172049b29b52105b0218d0f4"
          }
        },
        "c8b13715adab4572bdd3226a1476b317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a88d80d2d53945439403a1805b6d75e9",
            "placeholder": "​",
            "style": "IPY_MODEL_89f558840cbe4a8b9c64fdae330730df",
            "value": "modules.json: 100%"
          }
        },
        "539bc31905b8444e97e50ded4da26868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e4c1718b1b34ff2a4812e5e7d820b18",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5743e4c5f5764e1cac72a3f9e727f6ab",
            "value": 349
          }
        },
        "8a43a2fcb8a9492eaea0cb472816e8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e30d5b829e54de59110f7d00b6fe670",
            "placeholder": "​",
            "style": "IPY_MODEL_20b8834708154f25a7b11cd8cfb7a555",
            "value": " 349/349 [00:00&lt;00:00, 19.5kB/s]"
          }
        },
        "41ed5295172049b29b52105b0218d0f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88d80d2d53945439403a1805b6d75e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f558840cbe4a8b9c64fdae330730df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e4c1718b1b34ff2a4812e5e7d820b18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5743e4c5f5764e1cac72a3f9e727f6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e30d5b829e54de59110f7d00b6fe670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20b8834708154f25a7b11cd8cfb7a555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c227b71a0b1468e9d670996d37a831f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29b5e0274bcd4efbb3ca0c8014acdee6",
              "IPY_MODEL_8b95dbf85fba4a9c85096ca2c574cd52",
              "IPY_MODEL_7f64209ecc494914bc508c3fef892106"
            ],
            "layout": "IPY_MODEL_cfe86a61ff66479295509e0b24904ffe"
          }
        },
        "29b5e0274bcd4efbb3ca0c8014acdee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea3b8e279d0342e299c82d439badc1ae",
            "placeholder": "​",
            "style": "IPY_MODEL_6c6d07a3ba344ebbb292ac55ccce5f00",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "8b95dbf85fba4a9c85096ca2c574cd52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235858a5a3044b159b58fcd1a842222e",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_618e7ffd662245639236c66d5b7f44cf",
            "value": 116
          }
        },
        "7f64209ecc494914bc508c3fef892106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869d01057c2042f29c5d09a0a95d49a0",
            "placeholder": "​",
            "style": "IPY_MODEL_89f04a16e2754afdb0b604d0c14e6fce",
            "value": " 116/116 [00:00&lt;00:00, 7.58kB/s]"
          }
        },
        "cfe86a61ff66479295509e0b24904ffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3b8e279d0342e299c82d439badc1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c6d07a3ba344ebbb292ac55ccce5f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "235858a5a3044b159b58fcd1a842222e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618e7ffd662245639236c66d5b7f44cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "869d01057c2042f29c5d09a0a95d49a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f04a16e2754afdb0b604d0c14e6fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed4bb090e74f4b5bb5ae336b32a65e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ada8fb1c11db4df6b275c68989893a11",
              "IPY_MODEL_26f776e5cdf84e3494b16181f09ac04d",
              "IPY_MODEL_7f99cc5b424a4102a19b2bdc44bfad8e"
            ],
            "layout": "IPY_MODEL_d4b68b7fe2814d6784fa50d4c60ed8ec"
          }
        },
        "ada8fb1c11db4df6b275c68989893a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_372a5a2303d940c8bd8d4fe47864d499",
            "placeholder": "​",
            "style": "IPY_MODEL_52fbf79518da4a30a0a53f385a635682",
            "value": "README.md: 100%"
          }
        },
        "26f776e5cdf84e3494b16181f09ac04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f0d4acfd1d449559829bc2998d92adf",
            "max": 10415,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15a17b5559a44bc2b16f332ebb1da7e0",
            "value": 10415
          }
        },
        "7f99cc5b424a4102a19b2bdc44bfad8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed5ba76f5784896b418c255e530dafb",
            "placeholder": "​",
            "style": "IPY_MODEL_acdf6a06bf4847da924991a1978c1b02",
            "value": " 10.4k/10.4k [00:00&lt;00:00, 787kB/s]"
          }
        },
        "d4b68b7fe2814d6784fa50d4c60ed8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "372a5a2303d940c8bd8d4fe47864d499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52fbf79518da4a30a0a53f385a635682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f0d4acfd1d449559829bc2998d92adf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a17b5559a44bc2b16f332ebb1da7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ed5ba76f5784896b418c255e530dafb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acdf6a06bf4847da924991a1978c1b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67609b6302e64a1b9a804b976b7265e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ebfc303d9fa454590745984f8b2233d",
              "IPY_MODEL_591ba499aa714df6bf50ec95fe2ae8fc",
              "IPY_MODEL_3119757f136a47b0aa9c4537d95bb806"
            ],
            "layout": "IPY_MODEL_96276a6ee68c48d7a8ea901c3dcae718"
          }
        },
        "1ebfc303d9fa454590745984f8b2233d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c625828432e4658a49b847cb4ad58dc",
            "placeholder": "​",
            "style": "IPY_MODEL_52b27bca78654fc4b77a74fc4117448a",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "591ba499aa714df6bf50ec95fe2ae8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20ac2ab2883b4dcd8dacd6550455942f",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aab8d19bda0c4e7e9f5d6bd975d0045e",
            "value": 53
          }
        },
        "3119757f136a47b0aa9c4537d95bb806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1bb4eb2974f42bc9da21cd4d2317598",
            "placeholder": "​",
            "style": "IPY_MODEL_a31d34408e124dcea724400442a11cd1",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.23kB/s]"
          }
        },
        "96276a6ee68c48d7a8ea901c3dcae718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c625828432e4658a49b847cb4ad58dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b27bca78654fc4b77a74fc4117448a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20ac2ab2883b4dcd8dacd6550455942f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aab8d19bda0c4e7e9f5d6bd975d0045e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1bb4eb2974f42bc9da21cd4d2317598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a31d34408e124dcea724400442a11cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "718a3db278f84a49ad3d48cc2aa2df0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ac09677e4134c2581a4d4982833fc2d",
              "IPY_MODEL_d0dca2d6f17946608cd1f72666556cc8",
              "IPY_MODEL_05e6aaa90c7d450787fd4346d64a560d"
            ],
            "layout": "IPY_MODEL_2d36f8c5dca046c0ab449d8ec158d05c"
          }
        },
        "0ac09677e4134c2581a4d4982833fc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f56a48e7ec046368c4963c1b21af15f",
            "placeholder": "​",
            "style": "IPY_MODEL_a491fd70160c43d08051b827b90693c4",
            "value": "config.json: 100%"
          }
        },
        "d0dca2d6f17946608cd1f72666556cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5485c5b47f864040a2dcf2975acbe766",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13b0cad7b12342cfa6017eff874e0d03",
            "value": 571
          }
        },
        "05e6aaa90c7d450787fd4346d64a560d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19d3372357834d4395ed5c4c3f526e7f",
            "placeholder": "​",
            "style": "IPY_MODEL_5d9e7663bbda411facfd7c691e59b047",
            "value": " 571/571 [00:00&lt;00:00, 53.9kB/s]"
          }
        },
        "2d36f8c5dca046c0ab449d8ec158d05c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f56a48e7ec046368c4963c1b21af15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a491fd70160c43d08051b827b90693c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5485c5b47f864040a2dcf2975acbe766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b0cad7b12342cfa6017eff874e0d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19d3372357834d4395ed5c4c3f526e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d9e7663bbda411facfd7c691e59b047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abaae453fd274a409503c4dc042a6efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0b41ebb2d3d48ff9b677c8cfcffc3c7",
              "IPY_MODEL_0c52aba73e504a3c84c7548f456cc6c4",
              "IPY_MODEL_28d9c4ea8534479d871eda1619133d4a"
            ],
            "layout": "IPY_MODEL_15d50312162d48619bbbac63e21498b4"
          }
        },
        "d0b41ebb2d3d48ff9b677c8cfcffc3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f087f04fe25f4fa4ae1fb90e41891f62",
            "placeholder": "​",
            "style": "IPY_MODEL_496f4ce792144e09b065d93ee0575dcf",
            "value": "model.safetensors: 100%"
          }
        },
        "0c52aba73e504a3c84c7548f456cc6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fa0b1ffa1224436b1334423d3627ef8",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43898fb9042c4fb19fe929942000e3b5",
            "value": 437971872
          }
        },
        "28d9c4ea8534479d871eda1619133d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274bf61fbb77448a9b154e38b38307ee",
            "placeholder": "​",
            "style": "IPY_MODEL_e2303c0f6bcb4ae0a69f0f17f2ca50f1",
            "value": " 438M/438M [00:03&lt;00:00, 137MB/s]"
          }
        },
        "15d50312162d48619bbbac63e21498b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f087f04fe25f4fa4ae1fb90e41891f62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "496f4ce792144e09b065d93ee0575dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fa0b1ffa1224436b1334423d3627ef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43898fb9042c4fb19fe929942000e3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "274bf61fbb77448a9b154e38b38307ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2303c0f6bcb4ae0a69f0f17f2ca50f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d850c8e025f54ebdbb801b845cec7ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4d50c02c87e433eba1a95efc9a1ed70",
              "IPY_MODEL_2db59d15d56a432a838d57299a81796c",
              "IPY_MODEL_94c4f195ffff4198891545bc4641ab78"
            ],
            "layout": "IPY_MODEL_c7399108bafe42f18881be5c62e76feb"
          }
        },
        "a4d50c02c87e433eba1a95efc9a1ed70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63ba34c34002418f8328dac4716a4798",
            "placeholder": "​",
            "style": "IPY_MODEL_58bec4845af0430788ff0cb2f2747665",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2db59d15d56a432a838d57299a81796c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cedeb1ebdc8c47c99414505599f631e8",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_453efef71957494cb93fa76c1c8f51ef",
            "value": 363
          }
        },
        "94c4f195ffff4198891545bc4641ab78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf2c7ff83aaf4a51a8f2439f078ed3ef",
            "placeholder": "​",
            "style": "IPY_MODEL_a4a0e57980344144a71d43d1ef757b98",
            "value": " 363/363 [00:00&lt;00:00, 30.8kB/s]"
          }
        },
        "c7399108bafe42f18881be5c62e76feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ba34c34002418f8328dac4716a4798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58bec4845af0430788ff0cb2f2747665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cedeb1ebdc8c47c99414505599f631e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "453efef71957494cb93fa76c1c8f51ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf2c7ff83aaf4a51a8f2439f078ed3ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a0e57980344144a71d43d1ef757b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f849efa6b584e94ad70ad0a7e3e4f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a00e489f4cf4cb98b6591a558b18a8d",
              "IPY_MODEL_fb48038b40324274996c2a43b699fedf",
              "IPY_MODEL_b7143af2ec074f5cb817512c12298694"
            ],
            "layout": "IPY_MODEL_8e6e6e0e37ff489f8c0ab2a7885c1aa3"
          }
        },
        "7a00e489f4cf4cb98b6591a558b18a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fd83527392b4fd18ebb410fef50eb4f",
            "placeholder": "​",
            "style": "IPY_MODEL_b268682c60934e0fa6e3add40b05c373",
            "value": "vocab.txt: 100%"
          }
        },
        "fb48038b40324274996c2a43b699fedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3adfedbdc9c4698954dab5cf03fca4f",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8c1be01e37c430bb58f2fc8aac8548e",
            "value": 231536
          }
        },
        "b7143af2ec074f5cb817512c12298694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6aef7d431794ab0ad07fd09fd30f0e2",
            "placeholder": "​",
            "style": "IPY_MODEL_12da6ce1e03e4b0f8c78e02efb14ca22",
            "value": " 232k/232k [00:00&lt;00:00, 6.33MB/s]"
          }
        },
        "8e6e6e0e37ff489f8c0ab2a7885c1aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fd83527392b4fd18ebb410fef50eb4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b268682c60934e0fa6e3add40b05c373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3adfedbdc9c4698954dab5cf03fca4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8c1be01e37c430bb58f2fc8aac8548e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6aef7d431794ab0ad07fd09fd30f0e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12da6ce1e03e4b0f8c78e02efb14ca22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0024df2189b442f0ab3a776b628c6474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abc2e7ae8f94474e8a11ad91c9640681",
              "IPY_MODEL_5bb8be20703a4d5f88f3ef0eda5b6d62",
              "IPY_MODEL_eabeb311135a4ef39d03a18b052996e4"
            ],
            "layout": "IPY_MODEL_d0e2c3f82f244bf78456f377f847c9ae"
          }
        },
        "abc2e7ae8f94474e8a11ad91c9640681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40d370417a7a4ac7b91b84e38e921adc",
            "placeholder": "​",
            "style": "IPY_MODEL_d00ecde2e4204c7ba31cfda5c39377ef",
            "value": "tokenizer.json: 100%"
          }
        },
        "5bb8be20703a4d5f88f3ef0eda5b6d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffbcdbb659444ee0bd80e53193343f44",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e661013d5d394294a47bbe09b5b7443a",
            "value": 466021
          }
        },
        "eabeb311135a4ef39d03a18b052996e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6106558b49664abbaf79adb80309a9b3",
            "placeholder": "​",
            "style": "IPY_MODEL_d67dd6a753ec4fe1918335d43e210118",
            "value": " 466k/466k [00:00&lt;00:00, 1.12MB/s]"
          }
        },
        "d0e2c3f82f244bf78456f377f847c9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d370417a7a4ac7b91b84e38e921adc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d00ecde2e4204c7ba31cfda5c39377ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffbcdbb659444ee0bd80e53193343f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e661013d5d394294a47bbe09b5b7443a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6106558b49664abbaf79adb80309a9b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d67dd6a753ec4fe1918335d43e210118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed34dff1d9744c10ad6488c25ddda184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2933a814069a4e82821ca9e96bf09d66",
              "IPY_MODEL_063f0eeccae74618b83bb0c17653482a",
              "IPY_MODEL_edecef746ba941efb7e8255d2ff2da57"
            ],
            "layout": "IPY_MODEL_df666f0d1d2347ba9a6b51cf699b9757"
          }
        },
        "2933a814069a4e82821ca9e96bf09d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc9284383524c2089d07c3d2ff0bc96",
            "placeholder": "​",
            "style": "IPY_MODEL_d1bc6a5b5d044269adf495d822927086",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "063f0eeccae74618b83bb0c17653482a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dedc7ce78334ccdba653076b907af4e",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af5a967d26e14eaa89f84388e1c52d6d",
            "value": 239
          }
        },
        "edecef746ba941efb7e8255d2ff2da57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a8f8f721858450bb0c1ffaa389a3c4d",
            "placeholder": "​",
            "style": "IPY_MODEL_87e5124ed0ea45409d0f9c6db2cc0f32",
            "value": " 239/239 [00:00&lt;00:00, 17.6kB/s]"
          }
        },
        "df666f0d1d2347ba9a6b51cf699b9757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccc9284383524c2089d07c3d2ff0bc96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1bc6a5b5d044269adf495d822927086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dedc7ce78334ccdba653076b907af4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af5a967d26e14eaa89f84388e1c52d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a8f8f721858450bb0c1ffaa389a3c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e5124ed0ea45409d0f9c6db2cc0f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "148479a91f144613a3c83b08aea0a7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23ec4fb621d0477ca9346ae755316615",
              "IPY_MODEL_89a72b0566864825b493222445957d49",
              "IPY_MODEL_fa58767370314913a30340b5977c9736"
            ],
            "layout": "IPY_MODEL_0c0f6bf94b254495a2923fa88a11b84a"
          }
        },
        "23ec4fb621d0477ca9346ae755316615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff6135df1ac34a4bb90b24cae818352d",
            "placeholder": "​",
            "style": "IPY_MODEL_cc4920cbca6d4b72aeeed22742fadae1",
            "value": "config.json: 100%"
          }
        },
        "89a72b0566864825b493222445957d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c1d928808884bb782ccb03ceb302548",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef086b57b58946e1a653d22f07ce8c1d",
            "value": 190
          }
        },
        "fa58767370314913a30340b5977c9736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d5660912f447888df3be0ff2babdda",
            "placeholder": "​",
            "style": "IPY_MODEL_4de31091cd314b72a52503ed3b8338da",
            "value": " 190/190 [00:00&lt;00:00, 13.8kB/s]"
          }
        },
        "0c0f6bf94b254495a2923fa88a11b84a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff6135df1ac34a4bb90b24cae818352d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4920cbca6d4b72aeeed22742fadae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c1d928808884bb782ccb03ceb302548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef086b57b58946e1a653d22f07ce8c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76d5660912f447888df3be0ff2babdda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de31091cd314b72a52503ed3b8338da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjoBHTSau89v",
        "outputId": "a1d88ee6-f239-4bc4-b2ed-4d93748e4524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.40.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.40 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.40->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (2.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading PennyLane-0.40.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.0 diastatic-malt-2.15.2 pennylane-0.40.0 pennylane-lightning-0.40.0 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n"
          ]
        }
      ],
      "source": [
        "pip install pennylane"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I. Encoding Text Data for QNLP\n",
        "\n",
        "This is arguably the trickiest part. Here's a breakdown of popular encoding methods for text, along with their strengths, weaknesses, and suitability for RAG:\n",
        "\n",
        "    A. Basis Encoding (One-Hot Encoding)\n",
        "\n",
        "        Concept: Assign each word in your vocabulary a unique basis state (e.g., |000> for \"the,\" |001> for \"cat,\" |010> for \"sat,\" etc.). A document becomes a superposition of the basis states representing its constituent words. You'd need n qubits to represent a vocabulary of size 2^n.\n",
        "\n",
        "        Pros: Simple to understand.\n",
        "\n",
        "        Cons:\n",
        "\n",
        "            Exponential Scaling: Requires an exponentially large number of qubits to represent even moderately sized vocabularies. Completely impractical for real-world text.\n",
        "\n",
        "            No Semantic Similarity: Words encoded in this way have no inherent relationship. \"Cat\" and \"Dog\" are as different as \"Cat\" and \"Hydrogen.\" This makes similarity comparisons useless.\n",
        "\n",
        "        Suitability for RAG: Unsuitable due to scaling and lack of semantic meaning. Avoid this for any practical QNLP task.\n",
        "\n",
        "    B. Amplitude Encoding\n",
        "\n",
        "        Concept: Encode the values of a classical vector (e.g., word counts, TF-IDF scores, pre-trained word embeddings) into the amplitudes of a quantum state. If your vector is [a1, a2, ..., an], the quantum state becomes:\n",
        "\n",
        "              \n",
        "        |ψ> = a1|00...0> + a2|00...1> + ... + an|11...1>\n",
        "\n",
        "            \n",
        "\n",
        "        IGNORE_WHEN_COPYING_START\n",
        "\n",
        "    Use code with caution.\n",
        "    IGNORE_WHEN_COPYING_END\n",
        "\n",
        "    Crucially, the amplitudes must be normalized such that a1^2 + a2^2 + ... + an^2 = 1. This represents a valid quantum state.\n",
        "\n",
        "    Pros:\n",
        "\n",
        "        Efficient Qubit Usage: Can encode 2^n values using only n qubits. This is a significant advantage over basis encoding.\n",
        "\n",
        "        Potential for Speedup: Quantum algorithms can operate directly on the amplitudes, offering potential computational advantages.\n",
        "\n",
        "    Cons:\n",
        "\n",
        "        State Preparation Complexity: Preparing the quantum state with the desired amplitudes can be challenging and may require complex quantum circuits (e.g., using Quantum Random Access Memory or QRAM, which is still largely theoretical). This is a major bottleneck.\n",
        "\n",
        "        Measurement Challenges: Retrieving the encoded data requires careful measurements, and the outcome is probabilistic.\n",
        "\n",
        "    Suitability for RAG: Potentially useful, especially if you're working with pre-computed embeddings from a classical model (e.g., Word2Vec, GloVe, or even sentence embeddings like Sentence-BERT). You could encode these embeddings into quantum states. The challenge is the state preparation complexity.\n",
        "\n",
        "C. Angle Encoding\n",
        "\n",
        "    Concept: Encode data into the angles of qubits. For example, a single data point x can be encoded as:\n",
        "\n",
        "          \n",
        "    |ψ> = cos(x) |0> + sin(x) |1>\n",
        "\n",
        "        \n",
        "\n",
        "    IGNORE_WHEN_COPYING_START\n",
        "\n",
        "        Use code with caution.\n",
        "        IGNORE_WHEN_COPYING_END\n",
        "\n",
        "        For a vector, you'd encode each element into the angle of a different qubit. You can also encode multiple features into a single qubit using a more complex rotation.\n",
        "\n",
        "        Pros:\n",
        "\n",
        "            Relatively Simple State Preparation: Easier to implement on near-term quantum hardware compared to amplitude encoding, as it mainly involves single-qubit rotations.\n",
        "\n",
        "            Data is in Rotation Angles: Allows use of quantum rotation gates to perform computations.\n",
        "\n",
        "        Cons:\n",
        "\n",
        "            Limited Encoding Capacity: Each qubit typically encodes only one or two data points.\n",
        "\n",
        "            Sensitivity to Noise: Quantum noise can easily corrupt the angle information.\n",
        "\n",
        "        Suitability for RAG: Can be used for encoding smaller feature vectors or for implementing specific quantum kernels. It may be suitable for representing the relevance scores or attention weights.\n",
        "\n",
        "    D. Quantum Feature Maps (Variational Quantum Circuits)\n",
        "\n",
        "        Concept: Use a parameterized quantum circuit to map classical data into a high-dimensional quantum Hilbert space. The circuit's parameters are trained to create a feature map that separates different classes of data.\n",
        "\n",
        "        Pros:\n",
        "\n",
        "            Potential for Feature Engineering: The quantum circuit can implicitly create complex, non-linear features that might be difficult to engineer classically.\n",
        "\n",
        "            Flexibility: The circuit architecture and parameters can be tailored to the specific data.\n",
        "\n",
        "        Cons:\n",
        "\n",
        "            Training Complexity: Training these circuits (using Variational Quantum Eigensolver (VQE) or similar methods) is computationally expensive and can be challenging. Requires a hybrid quantum-classical approach.\n",
        "\n",
        "            Hardware Dependence: The optimal circuit architecture depends on the available quantum hardware.\n",
        "\n",
        "            Limited Theoretical Understanding: The exact nature of the learned feature map is often difficult to interpret.\n",
        "\n",
        "        Suitability for RAG: Potentially powerful for learning complex relationships between queries and documents. However, the training cost is significant. More suitable for tasks like document classification that may improve RAG.\n",
        "\n",
        "    E. Tensor Network Encoding\n",
        "\n",
        "        Concept: Represent text as a tensor network. This is particularly useful for capturing long-range dependencies in text. Each word can be represented as a tensor, and the relationships between words are encoded in the connections of the network.\n",
        "\n",
        "        Pros:\n",
        "\n",
        "            Efficient Representation of Long-Range Dependencies: Captures complex relationships between words and phrases.\n",
        "\n",
        "            Dimensionality Reduction: Can compress high-dimensional data into a lower-dimensional representation.\n",
        "\n",
        "        Cons:\n",
        "\n",
        "            Complex Implementation: Requires specialized knowledge of tensor networks.\n",
        "\n",
        "            Computational Overhead: Performing computations on tensor networks can be computationally expensive, even classically.\n",
        "\n",
        "        Suitability for RAG: Potentially useful for capturing contextual information and improving the accuracy of semantic search, but the complexity is high.\n",
        "\n",
        "II. Encoding Image Data\n",
        "\n",
        "Encoding images into quantum states can be achieved in a number of ways, mirroring the text encoding strategies:\n",
        "\n",
        "    A. Amplitude Encoding: Represent pixel values as amplitudes of a quantum state. If you have an image with N pixels, each with a grayscale value, you would need log2(N) qubits.\n",
        "\n",
        "        Pros: Efficient qubit usage.\n",
        "\n",
        "        Cons: State preparation complexity is high, especially for high-resolution images.\n",
        "\n",
        "    B. Angle Encoding: Encode pixel values into the angles of qubits.\n",
        "\n",
        "        Pros: Easier state preparation compared to amplitude encoding.\n",
        "\n",
        "        Cons: Limited encoding capacity. Each qubit can hold only a small amount of information. High number of qubits required for image features.\n",
        "\n",
        "    C. Flexible Representation of Quantum Images (FRQI)\n",
        "\n",
        "        Concept: Encodes both the color and the position information of each pixel into a quantum state. This is specifically designed for image data.\n",
        "\n",
        "        Pros: Efficiently encodes image data.\n",
        "\n",
        "        Cons: Can be complex to implement and manipulate.\n",
        "\n",
        "    D. Quantum Feature Maps: Similar to text, you can use variational quantum circuits to extract features from images. This can be applied to image recognition tasks.\n",
        "\n",
        "III. Retrieval in Quantum States\n",
        "\n",
        "Once you have your text and images encoded into quantum states, you need to retrieve relevant information. Here are some key approaches:\n",
        "\n",
        "    A. Quantum Similarity Measures: Calculate the similarity between the quantum state of a query and the quantum states of documents in your database. Common measures include:\n",
        "\n",
        "        State Fidelity: Measures the overlap between two quantum states. A fidelity of 1 indicates identical states, while 0 indicates orthogonal states. High fidelity implies high similarity.\n",
        "\n",
        "        Inner Product: Calculate the inner product (dot product) between two quantum state vectors.\n",
        "\n",
        "        Quantum Earth Mover's Distance (QEMD): A quantum version of the Earth Mover's Distance (also known as Wasserstein distance), which is a measure of the distance between two probability distributions.\n",
        "\n",
        "    B. Quantum Search Algorithms: Use algorithms like Grover's algorithm to efficiently search for relevant documents in your quantum database. Grover's algorithm can provide a quadratic speedup compared to classical search algorithms.\n",
        "\n",
        "    C. Quantum Associative Memory (QuAM): Store associations between queries and documents in a quantum memory. When a new query is presented, the QuAM can retrieve the associated documents.\n",
        "\n",
        "IV. Choosing the Right Encoding and Retrieval Method\n",
        "\n",
        "Here's a decision-making framework for your QNLP-RAG project:\n",
        "\n",
        "    Data Type: Consider the type of data you are working with (text, images, or both).\n",
        "\n",
        "    Feature Engineering: Decide whether to perform classical feature engineering (e.g., using word embeddings) before encoding or to rely on quantum feature maps to learn features. If using pre-trained embeddings, amplitude encoding becomes a more attractive option.\n",
        "\n",
        "    Quantum Hardware: Consider the limitations of available quantum hardware (number of qubits, connectivity, gate fidelity). Near-term devices (NISQ) are noisy and have limited qubit counts, so simpler encoding methods like angle encoding or shallower quantum circuits are more practical.\n",
        "\n",
        "    Computational Resources: Evaluate the computational cost of state preparation, quantum computations, and measurements.\n",
        "\n",
        "    Desired Speedup: Determine the level of speedup you are hoping to achieve. Grover's algorithm provides a quadratic speedup, but other quantum algorithms may offer different advantages.\n",
        "\n",
        "    Hybrid Approach: Consider a hybrid quantum-classical approach, where some computations are performed classically and others are performed on a quantum computer. For example, you could use classical machine learning to pre-process the data and then use a quantum computer to perform the similarity search.\n",
        "\n",
        "    State Preparation Complexity: Aim to prepare a simpler state preparation algorithm because it is often the bottleneck of quantum implementations\n",
        "\n",
        "Example Scenario and Implementation Tips\n",
        "\n",
        "Let's say you have a corpus of text documents and you want to build a QNLP-RAG system.\n",
        "\n",
        "    Step 1: Classical Pre-processing:\n",
        "\n",
        "        Use classical NLP techniques to pre-process the text data (e.g., tokenization, stemming, stop word removal).\n",
        "\n",
        "        Generate word embeddings (e.g., Word2Vec, GloVe, Sentence-BERT) for each document and query.\n",
        "\n",
        "    Step 2: Quantum Encoding:\n",
        "\n",
        "        Encode the word embeddings into quantum states using amplitude encoding. Normalize the embedding vectors to ensure they represent valid quantum states.\n",
        "\n",
        "    Step 3: Quantum Retrieval:\n",
        "\n",
        "        Calculate the state fidelity between the quantum state of the query and the quantum states of the documents in your database.\n",
        "\n",
        "        Use Grover's algorithm to efficiently search for the documents with the highest state fidelity.\n",
        "\n",
        "    Step 4: Classical Post-processing:\n",
        "\n",
        "        Retrieve the classical text documents that correspond to the most relevant quantum states.\n",
        "\n",
        "        Use classical NLP techniques to rank and present the retrieved documents to the user."
      ],
      "metadata": {
        "id": "e952uorJMj4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "# Example: Amplitude Encoding of a 2-dimensional vector\n",
        "dev = qml.device(\"default.qubit\", wires=1)  # Need 1 qubit for a 2-dim vector\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def amplitude_encoding(vector):\n",
        "    \"\"\"Encodes a normalized vector into the amplitudes of a quantum state.\"\"\"\n",
        "    qml.AmplitudeEmbedding(features=vector, wires=range(1), normalize=False)  #Normalization should happen before\n",
        "    return qml.state()\n",
        "\n",
        "# Example Usage\n",
        "embedding_vector = np.array([1/np.sqrt(2), 1/np.sqrt(2)]) #Normalized vector.\n",
        "quantum_state = amplitude_encoding(embedding_vector)\n",
        "print(quantum_state)\n",
        "# Example : Angle Encoding\n",
        "dev2 = qml.device(\"default.qubit\", wires=1)\n",
        "\n",
        "@qml.qnode(dev2)\n",
        "def angle_encoding(x):\n",
        "    qml.RY(x, wires=0) #RY rotation encodes the angle\n",
        "    return qml.expval(qml.PauliZ(wires=0)) #Example measurement\n",
        "\n",
        "angle = np.pi/4\n",
        "expectation_value = angle_encoding(angle)\n",
        "print(expectation_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXf6yUfvMkve",
        "outputId": "8461b869-6a40-4666-d7be-9018875463c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.70710678+0.j 0.70710678+0.j]\n",
            "0.7071067811865475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important Considerations:\n",
        "\n",
        "    Normalization: Always normalize your data before encoding it into quantum states, especially when using amplitude encoding.\n",
        "\n",
        "    Error Mitigation: Quantum noise is a major challenge. Explore error mitigation techniques to improve the accuracy of your results.\n",
        "\n",
        "    Hybrid Quantum-Classical Approach: In the near term, hybrid approaches are often the most practical.\n",
        "\n",
        "    Scalability: Keep scalability in mind when choosing an encoding method. Some methods scale exponentially with the size of the data, which can be a major limitation.\n",
        "\n",
        "    Benchmarking: Thoroughly benchmark your quantum algorithms against classical algorithms to determine whether you are actually achieving a speedup."
      ],
      "metadata": {
        "id": "EPPFhX9RQLTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Simplified Embeddings: The one-hot encoding-like embeddings are extremely basic. Real-world QNLP would use pre-trained word embeddings to capture semantic relationships.\n",
        "\n",
        "    Normalization: Crucial for amplitude encoding. The amplitudes must sum to 1 when squared.\n",
        "\n",
        "    Padding: Important to pad the vector to be a power of 2 to comply with Amplitude Encoding requirements\n",
        "\n",
        "    State Fidelity as Similarity: State fidelity is a basic similarity measure. More advanced quantum similarity measures exist.\n",
        "\n",
        "    Quantum Hardware Limitations: This example uses a simulator. Running this on real quantum hardware would be significantly more challenging due to noise and decoherence.\n",
        "\n",
        "    Scalability: This approach does not scale well to large corpora or vocabularies due to the qubit requirements of amplitude encoding.\n",
        "\n",
        "    Basic RAG: The answer is simply the retrieved document. A more sophisticated RAG system would use the retrieved document to generate a more concise and relevant answer. This would usually be done via a LLM."
      ],
      "metadata": {
        "id": "clud71F-Qpb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "\n",
        "# Download necessary NLTK resources (run this only once)\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "try:\n",
        "    word_tokenize(\"example text\")  # Attempt to tokenize to trigger download\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "# I. Sample Text Corpus\n",
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"The cat sat on the mat.\",\n",
        "    \"A dog is a loyal companion.\",\n",
        "    \"The fox is a cunning animal.\"\n",
        "]\n",
        "question = \"What does the fox do?\"\n",
        "\n",
        "# II. Classical Pre-processing\n",
        "def preprocess(text):\n",
        "    \"\"\"Tokenizes, removes stop words, and lowercases the text.\"\"\"\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w.lower() for w in tokens if w.isalpha()]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    return tokens\n",
        "\n",
        "processed_corpus = [preprocess(doc) for doc in corpus]\n",
        "processed_question = preprocess(question)\n",
        "\n",
        "# III. Creating a Vocabulary and Word Embeddings (Simplified)\n",
        "vocabulary = set()\n",
        "for doc in processed_corpus:\n",
        "    vocabulary.update(doc)\n",
        "vocabulary.update(processed_question)\n",
        "\n",
        "word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "index_to_word = {i: word for word, i in word_to_index.items()}\n",
        "vocab_size = len(vocabulary)\n",
        "\n",
        "def create_simple_embedding(tokens, vocab_size, word_to_index):\n",
        "    \"\"\"Creates a simple vector embedding based on word presence.\"\"\"\n",
        "    embedding = np.zeros(vocab_size)\n",
        "    for token in tokens:\n",
        "        if token in word_to_index:\n",
        "            embedding[word_to_index[token]] = 1\n",
        "    return embedding\n",
        "\n",
        "corpus_embeddings = [create_simple_embedding(doc, vocab_size, word_to_index) for doc in processed_corpus]\n",
        "question_embedding = create_simple_embedding(processed_question, vocab_size, word_to_index)\n",
        "\n",
        "def normalize_vector(vector):\n",
        "    norm = np.linalg.norm(vector)\n",
        "    if norm == 0:\n",
        "        return vector\n",
        "    return vector / norm\n",
        "\n",
        "normalized_corpus_embeddings = [normalize_vector(embedding) for embedding in corpus_embeddings]\n",
        "normalized_question_embedding = normalize_vector(question_embedding)\n",
        "\n",
        "# IV. Quantum Encoding (Amplitude Encoding)\n",
        "num_qubits = int(np.ceil(np.log2(vocab_size)))\n",
        "\n",
        "def pad_vector(vector, target_length):\n",
        "    current_length = len(vector)\n",
        "    if current_length < target_length:\n",
        "        padding_length = target_length - current_length\n",
        "        padding = np.zeros(padding_length)\n",
        "        padded_vector = np.concatenate((vector, padding))\n",
        "        return padded_vector\n",
        "    return vector\n",
        "\n",
        "padded_vocab_size = 2**num_qubits\n",
        "padded_corpus_embeddings = [pad_vector(embedding, padded_vocab_size) for embedding in normalized_corpus_embeddings]\n",
        "padded_question_embedding = pad_vector(normalized_question_embedding, padded_vocab_size)\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def amplitude_encode(embedding):\n",
        "    qml.AmplitudeEmbedding(features=embedding, wires=range(num_qubits), pad_with=0, normalize=False)\n",
        "    return qml.state()\n",
        "\n",
        "quantum_corpus_states = [amplitude_encode(embedding) for embedding in padded_corpus_embeddings]\n",
        "quantum_question_state = amplitude_encode(padded_question_embedding)\n",
        "\n",
        "# V. Quantum Retrieval (State Fidelity)\n",
        "def state_fidelity(state1, state2):\n",
        "    \"\"\"Calculates the fidelity between two quantum states.\"\"\"\n",
        "    overlap = np.abs(np.vdot(state1, state2))**2\n",
        "    return overlap\n",
        "\n",
        "similarities = [state_fidelity(quantum_question_state, state) for state in quantum_corpus_states]\n",
        "most_similar_index = np.argmax(similarities)\n",
        "\n",
        "retrieved_document = corpus[most_similar_index]\n",
        "\n",
        "# VI. Answering the Query\n",
        "print(f\"Query: {question}\")\n",
        "print(f\"Answer: {retrieved_document}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_OvUtcgQqlA",
        "outputId": "273b653e-52ac-424b-aadb-b941fc7daaa1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What does the fox do?\n",
            "Answer: The fox is a cunning animal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import requests, zipfile\n",
        "from shutil import copyfileobj\n",
        "\n",
        "# I. Setup and Downloads (GloVe and NLTK)\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "try:\n",
        "    word_tokenize(\"example text\")\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "glove_file = \"glove.6B.50d.txt\"\n",
        "url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "\n",
        "if not os.path.exists(glove_file):\n",
        "    print(\"Downloading GloVe embeddings...\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(\"glove.zip\", \"wb\") as out_file:\n",
        "        copyfileobj(response.raw, out_file)\n",
        "\n",
        "    print(\"Extracting GloVe embeddings...\")\n",
        "    with zipfile.ZipFile(\"glove.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "    os.remove(\"glove.zip\")\n",
        "\n",
        "# II. Load GloVe Embeddings\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_file)\n",
        "embedding_dim = len(next(iter(glove_embeddings.values())))\n",
        "print(f\"Loaded {len(glove_embeddings)} GloVe embeddings with dimension {embedding_dim}\")\n",
        "\n",
        "# III. Larger Text Corpus and Preprocessing\n",
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog. This is a classic English pangram.\",\n",
        "    \"The cat sat on the mat, peacefully napping in the sun.\",\n",
        "    \"A dog is a loyal companion, offering unconditional love and support. Dogs are good pets.\",\n",
        "    \"The fox is a cunning animal, known for its cleverness and adaptability. Foxes are often found in forests.\",\n",
        "    \"Quantum computing holds the promise of revolutionizing various fields, including medicine and materials science.\",\n",
        "    \"Natural language processing (NLP) is a branch of artificial intelligence that deals with the interaction between computers and humans using natural language.\",\n",
        "    \"The Earth is the third planet from the Sun and the only known planet to harbor life.\",\n",
        "    \"Artificial intelligence (AI) is rapidly transforming industries and reshaping the way we live and work.\",\n",
        "    \"Climate change is a pressing global issue, requiring urgent action to mitigate its effects.\",\n",
        "    \"Renewable energy sources, such as solar and wind power, are becoming increasingly important in the transition to a sustainable future.\"\n",
        "]\n",
        "question = \"What is NLP?\"\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w.lower() for w in tokens if w.isalpha()]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    return tokens\n",
        "\n",
        "processed_corpus = [preprocess(doc) for doc in corpus]\n",
        "processed_question = preprocess(question)\n",
        "\n",
        "# IV. Document and Query Embeddings (Using GloVe)\n",
        "def create_document_embedding(tokens, embeddings, embedding_dim):\n",
        "    word_vectors = [embeddings[token] for token in tokens if token in embeddings]\n",
        "    if not word_vectors:\n",
        "        return np.zeros(embedding_dim)\n",
        "    document_embedding = np.mean(word_vectors, axis=0)\n",
        "    return document_embedding\n",
        "\n",
        "corpus_embeddings = [create_document_embedding(doc, glove_embeddings, embedding_dim) for doc in processed_corpus]\n",
        "question_embedding = create_document_embedding(processed_question, glove_embeddings, embedding_dim)\n",
        "\n",
        "def normalize_vector(vector):\n",
        "    norm = np.linalg.norm(vector)\n",
        "    if norm == 0:\n",
        "        return vector\n",
        "    return vector / norm\n",
        "\n",
        "normalized_corpus_embeddings = [normalize_vector(embedding) for embedding in corpus_embeddings]\n",
        "normalized_question_embedding = normalize_vector(question_embedding)\n",
        "\n",
        "# V. Quantum Encoding (Amplitude Encoding)\n",
        "num_qubits = int(np.ceil(np.log2(embedding_dim)))\n",
        "padded_vocab_size = 2**num_qubits\n",
        "\n",
        "def pad_vector(vector, target_length):\n",
        "    current_length = len(vector)\n",
        "    if current_length < target_length:\n",
        "        padding_length = target_length - current_length\n",
        "        padding = np.zeros(padding_length)\n",
        "        padded_vector = np.concatenate((vector, padding))\n",
        "        return padded_vector\n",
        "    return vector\n",
        "\n",
        "padded_corpus_embeddings = [pad_vector(embedding, padded_vocab_size) for embedding in normalized_corpus_embeddings]\n",
        "padded_question_embedding = pad_vector(normalized_question_embedding, padded_vocab_size)\n",
        "\n",
        "# **IMPORTANT: Explicitly cast embeddings to real before quantum encoding**\n",
        "padded_corpus_embeddings = [embedding.astype(np.float64) for embedding in padded_corpus_embeddings]\n",
        "padded_question_embedding = padded_question_embedding.astype(np.float64)\n",
        "\n",
        "\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def amplitude_encode(embedding):\n",
        "    qml.AmplitudeEmbedding(features=embedding, wires=range(num_qubits), pad_with=0, normalize=False)\n",
        "    return qml.state()\n",
        "\n",
        "quantum_corpus_states = [amplitude_encode(embedding) for embedding in padded_corpus_embeddings]\n",
        "quantum_question_state = amplitude_encode(padded_question_embedding)\n",
        "\n",
        "# VI. Quantum Retrieval and Similarity (Cosine Similarity of Quantum States)\n",
        "def quantum_cosine_similarity(state1, state2):\n",
        "    # **IMPORTANT: Explicitly clip imaginary components to zero before cosine similarity**\n",
        "    state1 = np.real(state1)\n",
        "    state2 = np.real(state2)\n",
        "    similarity = cosine_similarity(state1.reshape(1,-1), state2.reshape(1,-1))[0][0]\n",
        "    return similarity\n",
        "\n",
        "similarities = [quantum_cosine_similarity(quantum_question_state, state) for state in quantum_corpus_states]\n",
        "most_similar_index = np.argmax(similarities)\n",
        "\n",
        "retrieved_document = corpus[most_similar_index]\n",
        "\n",
        "# VII. Answer Extraction (Basic)\n",
        "def extract_answer(document, question):\n",
        "    sentences = nltk.sent_tokenize(document)\n",
        "    question_embedding = create_document_embedding(preprocess(question), glove_embeddings, embedding_dim)\n",
        "    sentence_similarities = []\n",
        "    for sentence in sentences:\n",
        "        sentence_embedding = create_document_embedding(preprocess(sentence), glove_embeddings, embedding_dim)\n",
        "        similarity = cosine_similarity(question_embedding.reshape(1, -1), sentence_embedding.reshape(1, -1))[0][0]\n",
        "        sentence_similarities.append(similarity)\n",
        "    best_sentence_index = np.argmax(sentence_similarities)\n",
        "    return sentences[best_sentence_index]\n",
        "\n",
        "answer = extract_answer(retrieved_document, question)\n",
        "\n",
        "print(f\"Query: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOgubBlNR4pJ",
        "outputId": "6ab1a331-9983-4cea-aa28-ca5b51a35597"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 GloVe embeddings with dimension 50\n",
            "Query: What is NLP?\n",
            "Answer: Natural language processing (NLP) is a branch of artificial intelligence that deals with the interaction between computers and humans using natural language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is Quantum in the Code:\n",
        "\n",
        "    Amplitude Encoding: The AmplitudeEmbedding from PennyLane is used to encode classical data (the GloVe embeddings) into the amplitudes of a quantum state. This is a quantum representation of the data.\n",
        "\n",
        "    Quantum State Representation: The corpus and query are represented as quantum states.\n",
        "\n",
        "What is Classical in the Code:\n",
        "\n",
        "    GloVe Embeddings: The GloVe embeddings themselves are generated using a classical machine learning model. The semantics of the text are captured classically.\n",
        "\n",
        "    Preprocessing: Tokenization, stop word removal, and other preprocessing steps are performed classically.\n",
        "\n",
        "    Cosine Similarity: The cosine_similarity calculation from sklearn is a classical computation. Even though we are feeding it the quantum states, the actual similarity calculation is done classically.\n",
        "\n",
        "    Answer Extraction: The entire answer extraction process is classical.\n",
        "\n",
        "    Control Flow: The overall logic of the RAG system (retrieval, answer extraction) is implemented using classical Python code.\n",
        "\n",
        "What Would Make it Closer to a \"Complete\" Quantum RAG:\n",
        "\n",
        "A truly \"complete\" quantum RAG system would aim to leverage quantum algorithms and quantum data representations throughout the entire process, not just in the encoding step. Here are some key areas where quantum algorithms could be applied:\n",
        "\n",
        "    Quantum Embeddings: Instead of using classical GloVe embeddings, explore methods for generating quantum embeddings directly. This could involve training a variational quantum circuit (VQC) to learn a quantum feature map that maps text to a quantum state space. This is a research area and can be computationally expensive.\n",
        "\n",
        "    Quantum Similarity Search: The most promising area for potential quantum advantage is the similarity search. Replace the classical cosine_similarity calculation with a quantum algorithm for similarity search, such as:\n",
        "\n",
        "        Quantum Earth Mover's Distance (QEMD): A quantum version of Earth Mover's Distance, potentially offering a speedup for comparing probability distributions.\n",
        "\n",
        "        Quantum Nearest Neighbor Search: Quantum algorithms for nearest neighbor search, such as those based on Grover's algorithm, could be used to efficiently find the most similar documents in the quantum database. However, QRAM (Quantum Random Access Memory) is often assumed for these which is a challenge.\n",
        "\n",
        "        Quantum Inner Product Estimation: There are quantum algorithms that can estimate the inner product (related to cosine similarity) of two quantum states more efficiently than classical algorithms in some scenarios.\n",
        "\n",
        "    Quantum Natural Language Processing (QNLP) for Understanding: Use quantum algorithms to perform tasks such as:\n",
        "\n",
        "        Quantum Parsing: Develop quantum algorithms for parsing natural language sentences.\n",
        "\n",
        "        Quantum Semantic Analysis: Use quantum techniques to analyze the meaning of text.\n",
        "\n",
        "    Quantum Answer Generation: Explore methods for generating answers using quantum algorithms. This could involve:\n",
        "\n",
        "        Quantum Language Models: Train quantum language models to generate text. This is highly experimental.\n",
        "\n",
        "        Quantum Information Retrieval: Use quantum algorithms to retrieve relevant information from a knowledge base and combine it to generate an answer.\n",
        "\n",
        "Challenges and Considerations:\n",
        "\n",
        "    Qubit Requirements: Many quantum algorithms require a large number of qubits, which are not yet available on current quantum hardware.\n",
        "\n",
        "    Quantum Random Access Memory (QRAM): Some quantum algorithms, such as those based on Grover's algorithm, require QRAM, which is a theoretical technology that is not yet practical.\n",
        "\n",
        "    State Preparation Complexity: Preparing the quantum states required for many quantum algorithms can be computationally expensive.\n",
        "\n",
        "    Quantum Noise: Quantum computers are susceptible to noise, which can degrade the accuracy of quantum computations. Error correction is essential but adds overhead.\n",
        "\n",
        "    Lack of Mature QNLP Algorithms: The field of QNLP is still relatively new, and there are not yet many mature quantum algorithms available for natural language processing tasks.\n",
        "\n",
        "In summary:\n",
        "\n",
        "Your current code is a great starting point for exploring QNLP-RAG, but it's more accurately described as a quantum-enhanced or quantum-inspired RAG system rather than a \"complete\" quantum RAG system. To move closer to a complete quantum RAG, you would need to replace more of the classical components with quantum algorithms. This is a challenging but potentially rewarding area of research. The main bottleneck, realistically, is a lack of good quantum algorithms for many of the core tasks, and the hardware to run them effectively."
      ],
      "metadata": {
        "id": "0ztdkjgEUrmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import requests, zipfile\n",
        "from shutil import copyfileobj\n",
        "\n",
        "# I. Setup and Downloads (GloVe and NLTK)\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "try:\n",
        "    word_tokenize(\"example text\")\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "glove_file = \"glove.6B.50d.txt\"\n",
        "url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "\n",
        "if not os.path.exists(glove_file):\n",
        "    print(\"Downloading GloVe embeddings...\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(\"glove.zip\", \"wb\") as out_file:\n",
        "        copyfileobj(response.raw, out_file)\n",
        "\n",
        "    print(\"Extracting GloVe embeddings...\")\n",
        "    with zipfile.ZipFile(\"glove.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "    os.remove(\"glove.zip\")\n",
        "\n",
        "# II. Load GloVe Embeddings\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_file)\n",
        "embedding_dim = len(next(iter(glove_embeddings.values())))\n",
        "print(f\"Loaded {len(glove_embeddings)} GloVe embeddings with dimension {embedding_dim}\")\n",
        "\n",
        "# III. Larger Text Corpus and Preprocessing\n",
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog. This is a classic English pangram.\",\n",
        "    \"The cat sat on the mat, peacefully napping in the sun.\",\n",
        "    \"A dog is a loyal companion, offering unconditional love and support. Dogs are good pets.\",\n",
        "    \"The fox is a cunning animal, known for its cleverness and adaptability. Foxes are often found in forests.\",\n",
        "    \"Quantum computing holds the promise of revolutionizing various fields, including medicine and materials science.\",\n",
        "    \"Natural language processing (NLP) is a branch of artificial intelligence that deals with the interaction between computers and humans using natural language.\",\n",
        "    \"The Earth is the third planet from the Sun and the only known planet to harbor life.\",\n",
        "    \"Artificial intelligence (AI) is rapidly transforming industries and reshaping the way we live and work.\",\n",
        "    \"Climate change is a pressing global issue, requiring urgent action to mitigate its effects.\",\n",
        "    \"Renewable energy sources, such as solar and wind power, are becoming increasingly important in the transition to a sustainable future.\"\n",
        "]\n",
        "question = \"What is NLP?\"\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w.lower() for w in tokens if w.isalpha()]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    return tokens\n",
        "\n",
        "processed_corpus = [preprocess(doc) for doc in corpus]\n",
        "processed_question = preprocess(question)\n",
        "\n",
        "# IV. Document and Query Embeddings (Using GloVe)\n",
        "def create_document_embedding(tokens, embeddings, embedding_dim):\n",
        "    word_vectors = [embeddings[token] for token in tokens if token in embeddings]\n",
        "    if not word_vectors:\n",
        "        return np.zeros(embedding_dim)\n",
        "    document_embedding = np.mean(word_vectors, axis=0)\n",
        "    return document_embedding\n",
        "\n",
        "corpus_embeddings = [create_document_embedding(doc, glove_embeddings, embedding_dim) for doc in processed_corpus]\n",
        "question_embedding = create_document_embedding(processed_question, glove_embeddings, embedding_dim)\n",
        "\n",
        "def normalize_vector(vector):\n",
        "    norm = np.linalg.norm(vector)\n",
        "    if norm == 0:\n",
        "        return vector\n",
        "    return vector / norm\n",
        "\n",
        "normalized_corpus_embeddings = [normalize_vector(embedding) for embedding in corpus_embeddings]\n",
        "normalized_question_embedding = normalize_vector(question_embedding)\n",
        "\n",
        "# V. Quantum Encoding (Amplitude Encoding)\n",
        "num_qubits = int(np.ceil(np.log2(embedding_dim)))\n",
        "num_document_qubits = int(np.ceil(np.log2(len(corpus))))\n",
        "padded_vocab_size = 2**num_qubits\n",
        "\n",
        "def pad_vector(vector, target_length):\n",
        "    current_length = len(vector)\n",
        "    if current_length < target_length:\n",
        "        padding_length = target_length - current_length\n",
        "        padding = np.zeros(padding_length)\n",
        "        padded_vector = np.concatenate((vector, padding))\n",
        "        return padded_vector\n",
        "    return vector\n",
        "\n",
        "padded_corpus_embeddings = [pad_vector(embedding, padded_vocab_size) for embedding in normalized_corpus_embeddings]\n",
        "padded_question_embedding = pad_vector(normalized_question_embedding, padded_vocab_size)\n",
        "\n",
        "# Explicitly cast embeddings to real before quantum encoding\n",
        "padded_corpus_embeddings = [embedding.astype(np.float64) for embedding in padded_corpus_embeddings]\n",
        "padded_question_embedding = padded_question_embedding.astype(np.float64)\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits + num_document_qubits) # Additional qubits for document indexing\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def amplitude_encode(embedding, index_qubits):  # Added index_qubits argument\n",
        "    \"\"\"Encodes embedding and index into the quantum state.\"\"\"\n",
        "    qml.AmplitudeEmbedding(features=embedding, wires=range(num_qubits), pad_with=0, normalize=False)\n",
        "    qml.BasisState(index_qubits, wires=range(num_qubits, num_qubits + num_document_qubits))\n",
        "    return qml.state()\n",
        "\n",
        "quantum_corpus_states = [amplitude_encode(embedding, i) for i, embedding in enumerate(padded_corpus_embeddings)]\n",
        "quantum_question_state = amplitude_encode(padded_question_embedding, 0) # Index doesn't matter for question, as long as same device is used\n",
        "\n",
        "# VI. Quantum Retrieval (Grover's Algorithm)\n",
        "\n",
        "# Calculate cosine similarities classically for oracle (simulated QRAM)\n",
        "# Explicitly clip imaginary components to zero before cosine similarity\n",
        "similarities = [cosine_similarity(np.real(quantum_question_state[:padded_vocab_size]).reshape(1,-1), np.real(quantum_corpus_states[i][:padded_vocab_size]).reshape(1,-1))[0][0] for i in range(len(corpus))] # Clip states for similarity\n",
        "\n",
        "#Set the threshold\n",
        "threshold = np.mean(similarities)\n",
        "#Get Index of Document Qubits.\n",
        "document_qubit_index = num_qubits + num_document_qubits - 1\n",
        "\n",
        "def oracle(wires):\n",
        "    \"\"\"Oracle marks states with similarity above the threshold.\"\"\"\n",
        "    for i in range(len(corpus)):\n",
        "        if similarities[i] >= threshold: #threshold to check is cosine similarity is good enough\n",
        "            qml.FlipSign(wires=(document_qubit_index,), n=1)\n",
        "\n",
        "#Grover operator to amplify good states\n",
        "\n",
        "def grover_diffusion_op(wires):\n",
        "    \"\"\"Grover diffusion operator.\"\"\"\n",
        "    num_document_qubits = int(np.ceil(np.log2(len(corpus))))\n",
        "    if num_document_qubits < 2: #Grover diffusion operator needs at least two qubits\n",
        "        print(\"Need at least two document qubits for Grover diffusion operator.\")\n",
        "        return\n",
        "\n",
        "    #Apply Hadamard to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "    #Apply PauliX to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.PauliX(wires=wire)\n",
        "\n",
        "    # Apply CZ to the first two document qubits (Control and Target)\n",
        "    qml.CZ(wires=[num_qubits, num_qubits + 1])\n",
        "\n",
        "    #Apply PauliX to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.PauliX(wires=wire)\n",
        "\n",
        "    #Apply Hadamard to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def grover_search():\n",
        "    \"\"\"Grover's algorithm implementation.\"\"\"\n",
        "    # Superposition over document indices\n",
        "    num_document_qubits = int(np.ceil(np.log2(len(corpus))))\n",
        "    if num_document_qubits < 2:\n",
        "      print(\"Need at least two document qubits for Grover search.\")\n",
        "      return 0*np.ones(2**num_document_qubits)\n",
        "\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "    # Number of Grover iterations\n",
        "    N = len(corpus)\n",
        "    num_iterations = int(np.floor(np.pi/4*np.sqrt(N))) # Optimal iterations\n",
        "\n",
        "    #Grover iterations\n",
        "    for _ in range(num_iterations):\n",
        "        oracle(range(num_qubits + num_document_qubits)) #Apply Oracle to mark good states\n",
        "        grover_diffusion_op(range(num_qubits + num_document_qubits))\n",
        "\n",
        "    return qml.probs(wires=range(num_qubits, num_qubits + num_document_qubits)) #measure the probability of each document index\n",
        "\n",
        "# Perform Grover's search\n",
        "probabilities = grover_search()\n",
        "if isinstance(probabilities, int): # Check if grover_search returned 0 due to insufficient document qubits.\n",
        "    most_likely_index = 0\n",
        "else:\n",
        "    most_likely_index = np.argmax(probabilities)\n",
        "print(\"Most likely index:\", most_likely_index)\n",
        "\n",
        "retrieved_document = corpus[most_likely_index]\n",
        "\n",
        "# VII. Answer Extraction (Basic)\n",
        "def extract_answer(document, question):\n",
        "    sentences = nltk.sent_tokenize(document)\n",
        "    question_embedding = create_document_embedding(preprocess(question), glove_embeddings, embedding_dim)\n",
        "    sentence_similarities = []\n",
        "    for sentence in sentences:\n",
        "        sentence_embedding = create_document_embedding(preprocess(sentence), glove_embeddings, embedding_dim)\n",
        "        similarity = cosine_similarity(question_embedding.reshape(1, -1), sentence_embedding.reshape(1, -1))[0][0]\n",
        "        sentence_similarities.append(similarity)\n",
        "    best_sentence_index = np.argmax(sentence_similarities)\n",
        "    return sentences[best_sentence_index]\n",
        "\n",
        "answer = extract_answer(retrieved_document, question)\n",
        "\n",
        "print(f\"Query: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOYPoVhDUsdM",
        "outputId": "e7560821-aadd-4795-81d2-1e286d2ac7b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 GloVe embeddings with dimension 50\n",
            "Most likely index: 0\n",
            "Query: What is NLP?\n",
            "Answer: This is a classic English pangram.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Changes and Explanations:\n",
        "\n",
        "    Qubit Allocation: The PennyLane device now needs enough qubits for both the embedding and for representing the document indices in superposition. We add int(np.ceil(np.log2(len(corpus)))) additional qubits.\n",
        "\n",
        "    Encoding Index: The amplitude_encode function now also encodes the index of the document into the basis state of the additional qubits. This is necessary for Grover's algorithm to operate on the documents in superposition.\n",
        "\n",
        "    Classical Similarity Calculation (for Oracle): I've kept the classical cosine similarity calculation temporarily for the oracle. This is where the QRAM assumption comes into play. In a real quantum system, you'd want a quantum way to determine if a document is \"relevant\" to the query. I'm using the classical cosine similarity and a threshold to simulate the QRAM. The oracle checks if similarities[i] >= threshold: to determine which states to mark.\n",
        "\n",
        "    Oracle Implementation: The oracle function is the heart of Grover's algorithm. It flips the sign of the amplitude of the states that satisfy the search condition (i.e., the documents that are similar to the query based on the threshold).\n",
        "\n",
        "    Grover Diffusion Operator: Implemented to amplify the good states\n",
        "\n",
        "    grover_search Function: Implements the main Grover's search algorithm:\n",
        "\n",
        "        Creates a superposition over all document indices using Hadamard gates.\n",
        "\n",
        "        Applies the oracle to mark the \"good\" states.\n",
        "\n",
        "        Applies the Grover diffusion operator to amplify the amplitudes of the \"good\" states.\n",
        "\n",
        "        Repeats the oracle and diffusion operator a calculated number of times for optimal amplification.\n",
        "\n",
        "        Measures the document index qubits to determine the most likely index.\n",
        "\n",
        "    Measurement: qml.probs is used to measure the probability of each document index after Grover's algorithm has been applied. The index with the highest probability is the most likely answer.\n",
        "\n",
        "How this code gets closer to a complete quantum implementation:\n",
        "\n",
        "    Grover's Algorithm: We've replaced the classical linear search with Grover's algorithm, providing a potential quadratic speedup.\n",
        "\n",
        "    Quantum State Manipulation: Grover's algorithm operates directly on the quantum states of the documents, leveraging quantum superposition and interference.\n",
        "\n",
        "Still Missing for a \"Complete\" Quantum RAG:\n",
        "\n",
        "    Quantum Oracle: The biggest missing piece is a quantum oracle. Using a classical similarity measure to define the oracle means we're still relying on classical computation for a critical step. Ideally, the oracle would be based on a purely quantum similarity measure or a learned quantum feature map.\n",
        "\n",
        "    True QRAM: We're simulating QRAM. True QRAM is a significant hardware challenge.\n",
        "\n",
        "    Quantum Embeddings: Starting with quantum embeddings from the beginning would truly make it a quantum system.\n",
        "\n",
        "This Grover's search based example is a step closer to a \"complete\" quantum RAG system, but it still has limitations. It highlights the challenges and opportunities in this exciting field. Remember that this is a research area, and practical quantum RAG systems are still years away.\n"
      ],
      "metadata": {
        "id": "spZuBj4MU7SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import requests, zipfile\n",
        "from shutil import copyfileobj\n",
        "\n",
        "# I. Setup and Downloads (GloVe and NLTK)\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "try:\n",
        "    word_tokenize(\"example text\")\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "glove_file = \"glove.6B.50d.txt\"\n",
        "url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "\n",
        "if not os.path.exists(glove_file):\n",
        "    print(\"Downloading GloVe embeddings...\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(\"glove.zip\", \"wb\") as out_file:\n",
        "        copyfileobj(response.raw, out_file)\n",
        "\n",
        "    print(\"Extracting GloVe embeddings...\")\n",
        "    with zipfile.ZipFile(\"glove.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "    os.remove(\"glove.zip\")\n",
        "\n",
        "# II. Load GloVe Embeddings\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_file)\n",
        "embedding_dim = len(next(iter(glove_embeddings.values())))\n",
        "print(f\"Loaded {len(glove_embeddings)} GloVe embeddings with dimension {embedding_dim}\")\n",
        "\n",
        "# III. Larger Text Corpus and Preprocessing\n",
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog. This is a classic English pangram.\",\n",
        "    \"The cat sat on the mat, peacefully napping in the sun.\",\n",
        "    \"A dog is a loyal companion, offering unconditional love and support. Dogs are good pets.\",\n",
        "    \"The fox is a cunning animal, known for its cleverness and adaptability. Foxes are often found in forests.\",\n",
        "    \"Quantum computing holds the promise of revolutionizing various fields, including medicine and materials science.\",\n",
        "    \"Natural language processing (NLP) is a branch of artificial intelligence that deals with the interaction between computers and humans using natural language.\",\n",
        "    \"The Earth is the third planet from the Sun and the only known planet to harbor life.\",\n",
        "    \"Artificial intelligence (AI) is rapidly transforming industries and reshaping the way we live and work.\",\n",
        "    \"Climate change is a pressing global issue, requiring urgent action to mitigate its effects.\",\n",
        "    \"Renewable energy sources, such as solar and wind power, are becoming increasingly important in the transition to a sustainable future.\"\n",
        "]\n",
        "\n",
        "# Get user query from the command line\n",
        "question = input(\"Enter your query: \")\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w.lower() for w in tokens if w.isalpha()]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    return tokens\n",
        "\n",
        "processed_corpus = [preprocess(doc) for doc in corpus]\n",
        "processed_question = preprocess(question)\n",
        "\n",
        "# IV. Document and Query Embeddings (Using GloVe)\n",
        "def create_document_embedding(tokens, embeddings, embedding_dim):\n",
        "    word_vectors = [embeddings[token] for token in tokens if token in embeddings]\n",
        "    if not word_vectors:\n",
        "        return np.zeros(embedding_dim)\n",
        "    document_embedding = np.mean(word_vectors, axis=0)\n",
        "    return document_embedding\n",
        "\n",
        "corpus_embeddings = [create_document_embedding(doc, glove_embeddings, embedding_dim) for doc in processed_corpus]\n",
        "question_embedding = create_document_embedding(processed_question, glove_embeddings, embedding_dim)\n",
        "\n",
        "def normalize_vector(vector):\n",
        "    norm = np.linalg.norm(vector)\n",
        "    if norm == 0:\n",
        "        return vector\n",
        "    return vector / norm\n",
        "\n",
        "normalized_corpus_embeddings = [normalize_vector(embedding) for embedding in corpus_embeddings]\n",
        "normalized_question_embedding = normalize_vector(question_embedding)\n",
        "\n",
        "# V. Quantum Encoding (Amplitude Encoding)\n",
        "num_qubits = int(np.ceil(np.log2(embedding_dim)))\n",
        "num_document_qubits = int(np.ceil(np.log2(len(corpus))))\n",
        "padded_vocab_size = 2**num_qubits\n",
        "\n",
        "def pad_vector(vector, target_length):\n",
        "    current_length = len(vector)\n",
        "    if current_length < target_length:\n",
        "        padding_length = target_length - current_length\n",
        "        padding = np.zeros(padding_length)\n",
        "        padded_vector = np.concatenate((vector, padding))\n",
        "        return padded_vector\n",
        "    return vector\n",
        "\n",
        "padded_corpus_embeddings = [pad_vector(embedding, padded_vocab_size) for embedding in normalized_corpus_embeddings]\n",
        "padded_question_embedding = pad_vector(normalized_question_embedding, padded_vocab_size)\n",
        "\n",
        "# Explicitly cast embeddings to real before quantum encoding\n",
        "padded_corpus_embeddings = [embedding.astype(np.float64) for embedding in padded_corpus_embeddings]\n",
        "padded_question_embedding = padded_question_embedding.astype(np.float64)\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits + num_document_qubits) # Additional qubits for document indexing\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def amplitude_encode(embedding, index_qubits):  # Added index_qubits argument\n",
        "    \"\"\"Encodes embedding and index into the quantum state.\"\"\"\n",
        "    qml.AmplitudeEmbedding(features=embedding, wires=range(num_qubits), pad_with=0, normalize=False)\n",
        "    qml.BasisState(index_qubits, wires=range(num_qubits, num_qubits + num_document_qubits))\n",
        "    return qml.state()\n",
        "\n",
        "quantum_corpus_states = [amplitude_encode(embedding, i) for i, embedding in enumerate(padded_corpus_embeddings)]\n",
        "quantum_question_state = amplitude_encode(padded_question_embedding, 0) # Index doesn't matter for question, as long as same device is used\n",
        "\n",
        "# VI. Quantum Retrieval (Grover's Algorithm)\n",
        "\n",
        "# Calculate cosine similarities classically for oracle (simulated QRAM)\n",
        "# Explicitly clip imaginary components to zero before cosine similarity\n",
        "similarities = [cosine_similarity(np.real(quantum_question_state[:padded_vocab_size]).reshape(1,-1), np.real(quantum_corpus_states[i][:padded_vocab_size]).reshape(1,-1))[0][0] for i in range(len(corpus))] # Clip states for similarity\n",
        "\n",
        "#Set the threshold\n",
        "threshold = np.mean(similarities)\n",
        "#Get Index of Document Qubits.\n",
        "document_qubit_index = num_qubits + num_document_qubits - 1\n",
        "\n",
        "def oracle(wires):\n",
        "    \"\"\"Oracle marks states with similarity above the threshold.\"\"\"\n",
        "    for i in range(len(corpus)):\n",
        "        if similarities[i] >= threshold: #threshold to check is cosine similarity is good enough\n",
        "            qml.FlipSign(wires=(document_qubit_index,), n=1)\n",
        "\n",
        "#Grover operator to amplify good states\n",
        "\n",
        "def grover_diffusion_op(wires):\n",
        "    \"\"\"Grover diffusion operator.\"\"\"\n",
        "    num_document_qubits = int(np.ceil(np.log2(len(corpus))))\n",
        "    if num_document_qubits < 2: #Grover diffusion operator needs at least two qubits\n",
        "        print(\"Need at least two document qubits for Grover diffusion operator.\")\n",
        "        return\n",
        "\n",
        "    #Apply Hadamard to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "    #Apply PauliX to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.PauliX(wires=wire)\n",
        "\n",
        "    # Apply CZ to the first two document qubits (Control and Target)\n",
        "    qml.CZ(wires=[num_qubits, num_qubits + 1])\n",
        "\n",
        "    #Apply PauliX to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.PauliX(wires=wire)\n",
        "\n",
        "    #Apply Hadamard to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def grover_search():\n",
        "    \"\"\"Grover's algorithm implementation.\"\"\"\n",
        "    # Superposition over document indices\n",
        "    num_document_qubits = int(np.ceil(np.log2(len(corpus))))\n",
        "    if num_document_qubits < 2:\n",
        "      print(\"Need at least two document qubits for Grover search.\")\n",
        "      return 0*np.ones(2**num_document_qubits)\n",
        "\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "    # Number of Grover iterations\n",
        "    N = len(corpus)\n",
        "    num_iterations = int(np.floor(np.pi/4*np.sqrt(N))) # Optimal iterations\n",
        "\n",
        "    #Grover iterations\n",
        "    for _ in range(num_iterations):\n",
        "        oracle(range(num_qubits + num_document_qubits)) #Apply Oracle to mark good states\n",
        "        grover_diffusion_op(range(num_qubits + num_document_qubits))\n",
        "\n",
        "    return qml.probs(wires=range(num_qubits, num_qubits + num_document_qubits)) #measure the probability of each document index\n",
        "\n",
        "# Perform Grover's search\n",
        "probabilities = grover_search()\n",
        "if isinstance(probabilities, int): # Check if grover_search returned 0 due to insufficient document qubits.\n",
        "    most_likely_index = 0\n",
        "else:\n",
        "    most_likely_index = np.argmax(probabilities)\n",
        "print(\"Most likely index:\", most_likely_index)\n",
        "\n",
        "retrieved_document = corpus[most_likely_index]\n",
        "\n",
        "# VII. Answer Extraction (Basic)\n",
        "def extract_answer(document, question):\n",
        "    sentences = nltk.sent_tokenize(document)\n",
        "    question_embedding = create_document_embedding(preprocess(question), glove_embeddings, embedding_dim)\n",
        "    sentence_similarities = []\n",
        "    for sentence in sentences:\n",
        "        sentence_embedding = create_document_embedding(preprocess(sentence), glove_embeddings, embedding_dim)\n",
        "        similarity = cosine_similarity(question_embedding.reshape(1, -1), sentence_embedding.reshape(1, -1))[0][0]\n",
        "        sentence_similarities.append(similarity)\n",
        "    best_sentence_index = np.argmax(sentence_similarities)\n",
        "    return sentences[best_sentence_index]\n",
        "\n",
        "answer = extract_answer(retrieved_document, question)\n",
        "\n",
        "print(f\"Query: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecRv7cLwXIjq",
        "outputId": "fd965522-7bbc-4595-e384-eef6b5ae81af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 GloVe embeddings with dimension 50\n",
            "Enter your query: DOG\n",
            "Most likely index: 0\n",
            "Query: DOG\n",
            "Answer: The quick brown fox jumps over the lazy dog.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import requests, zipfile\n",
        "from shutil import copyfileobj\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# I. Setup and Downloads (NLTK and Sentence Transformers)\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "try:\n",
        "    word_tokenize(\"example text\")\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "\n",
        "# II. Load Sentence Transformer Model\n",
        "model = SentenceTransformer('all-mpnet-base-v2')\n",
        "embedding_dim = model.get_sentence_embedding_dimension() # Get Embedding Dimension\n",
        "print(f\"Loaded Sentence Transformer model with dimension {embedding_dim}\")\n",
        "\n",
        "# III. Larger Text Corpus and Preprocessing\n",
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog. This is a classic English pangram.\",\n",
        "    \"The cat sat on the mat, peacefully napping in the sun.\",\n",
        "    \"A dog is a loyal companion, offering unconditional love and support. Dogs are good pets.\",\n",
        "    \"The fox is a cunning animal, known for its cleverness and adaptability. Foxes are often found in forests.\",\n",
        "    \"Quantum computing holds the promise of revolutionizing various fields, including medicine and materials science.\",\n",
        "    \"Natural language processing (NLP) is a branch of artificial intelligence that deals with the interaction between computers and humans using natural language.\",\n",
        "    \"The Earth is the third planet from the Sun and the only known planet to harbor life.\",\n",
        "    \"Artificial intelligence (AI) is rapidly transforming industries and reshaping the way we live and work.\",\n",
        "    \"Climate change is a pressing global issue, requiring urgent action to mitigate its effects.\",\n",
        "    \"Renewable energy sources, such as solar and wind power, are becoming increasingly important in the transition to a sustainable future.\"\n",
        "]\n",
        "\n",
        "# Get user query from the command line\n",
        "question = input(\"Enter your query: \")\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w.lower() for w in tokens if w.isalpha()]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    return tokens\n",
        "\n",
        "processed_corpus = [preprocess(doc) for doc in corpus]\n",
        "processed_question = preprocess(question)\n",
        "\n",
        "# IV. Document and Query Embeddings (Using Sentence Transformers)\n",
        "corpus_embeddings = model.encode(corpus)  # Encode entire sentences\n",
        "question_embedding = model.encode(question)\n",
        "\n",
        "def normalize_vector(vector):\n",
        "    norm = np.linalg.norm(vector)\n",
        "    if norm == 0:\n",
        "        return vector\n",
        "    return vector / norm\n",
        "\n",
        "normalized_corpus_embeddings = [normalize_vector(embedding) for embedding in corpus_embeddings]\n",
        "normalized_question_embedding = normalize_vector(question_embedding)\n",
        "\n",
        "# V. Quantum Encoding (Amplitude Encoding)\n",
        "num_qubits = int(np.ceil(np.log2(embedding_dim)))\n",
        "num_document_qubits = int(np.ceil(np.log2(len(corpus))))\n",
        "padded_vocab_size = 2**num_qubits\n",
        "\n",
        "def pad_vector(vector, target_length):\n",
        "    current_length = len(vector)\n",
        "    if current_length < target_length:\n",
        "        padding_length = target_length - current_length\n",
        "        padding = np.zeros(padding_length)\n",
        "        padded_vector = np.concatenate((vector, padding))\n",
        "        return padded_vector\n",
        "    return vector\n",
        "\n",
        "padded_corpus_embeddings = [pad_vector(embedding, padded_vocab_size) for embedding in normalized_corpus_embeddings]\n",
        "padded_question_embedding = pad_vector(normalized_question_embedding, padded_vocab_size)\n",
        "\n",
        "# Explicitly cast embeddings to real before quantum encoding\n",
        "padded_corpus_embeddings = [embedding.astype(np.float64) for embedding in padded_corpus_embeddings]\n",
        "padded_question_embedding = padded_question_embedding.astype(np.float64)\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits + num_document_qubits) # Additional qubits for document indexing\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def amplitude_encode(embedding, index_qubits):  # Added index_qubits argument\n",
        "    \"\"\"Encodes embedding and index into the quantum state.\"\"\"\n",
        "    qml.AmplitudeEmbedding(features=embedding, wires=range(num_qubits), pad_with=0, normalize=False)\n",
        "    qml.BasisState(index_qubits, wires=range(num_qubits, num_qubits + num_document_qubits))\n",
        "    return qml.state()\n",
        "\n",
        "quantum_corpus_states = [amplitude_encode(embedding, i) for i, embedding in enumerate(padded_corpus_embeddings)]\n",
        "quantum_question_state = amplitude_encode(padded_question_embedding, 0) # Index doesn't matter for question, as long as same device is used\n",
        "\n",
        "# VI. Quantum Retrieval (Grover's Algorithm)\n",
        "\n",
        "# Calculate cosine similarities classically for oracle (simulated QRAM)\n",
        "# Explicitly clip imaginary components to zero before cosine similarity\n",
        "similarities = [cosine_similarity(np.real(quantum_question_state[:padded_vocab_size]).reshape(1,-1), np.real(quantum_corpus_states[i][:padded_vocab_size]).reshape(1,-1))[0][0] for i in range(len(corpus))] # Clip states for similarity\n",
        "\n",
        "#Set the threshold\n",
        "threshold = np.mean(similarities)\n",
        "#Get Index of Document Qubits.\n",
        "document_qubit_index = num_qubits + num_document_qubits - 1\n",
        "\n",
        "def oracle(wires):\n",
        "    \"\"\"Oracle marks states with similarity above the threshold.\"\"\"\n",
        "    for i in range(len(corpus)):\n",
        "        if similarities[i] >= threshold: #threshold to check is cosine similarity is good enough\n",
        "            qml.FlipSign(wires=(document_qubit_index,), n=1)\n",
        "\n",
        "#Grover operator to amplify good states\n",
        "\n",
        "def grover_diffusion_op(wires):\n",
        "    \"\"\"Grover diffusion operator.\"\"\"\n",
        "    num_document_qubits = int(np.ceil(np.log2(len(corpus))))\n",
        "    if num_document_qubits < 2: #Grover diffusion operator needs at least two qubits\n",
        "        print(\"Need at least two document qubits for Grover diffusion operator.\")\n",
        "        return\n",
        "\n",
        "    #Apply Hadamard to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "    #Apply PauliX to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.PauliX(wires=wire)\n",
        "\n",
        "    # Apply CZ to the first two document qubits (Control and Target)\n",
        "    qml.CZ(wires=[num_qubits, num_qubits + 1])\n",
        "\n",
        "    #Apply PauliX to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.PauliX(wires=wire)\n",
        "\n",
        "    #Apply Hadamard to all document index qubits\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def grover_search():\n",
        "    \"\"\"Grover's algorithm implementation.\"\"\"\n",
        "    # Superposition over document indices\n",
        "    num_document_qubits = int(np.ceil(np.log2(len(corpus))))\n",
        "    if num_document_qubits < 2:\n",
        "      print(\"Need at least two document qubits for Grover search.\")\n",
        "      return 0*np.ones(2**num_document_qubits)\n",
        "\n",
        "    for wire in range(num_qubits, num_qubits + num_document_qubits):\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "    # Number of Grover iterations\n",
        "    N = len(corpus)\n",
        "    num_iterations = int(np.floor(np.pi/4*np.sqrt(N))) # Optimal iterations\n",
        "\n",
        "    #Grover iterations\n",
        "    for _ in range(num_iterations):\n",
        "        oracle(range(num_qubits + num_document_qubits)) #Apply Oracle to mark good states\n",
        "        grover_diffusion_op(range(num_qubits + num_document_qubits))\n",
        "\n",
        "    return qml.probs(wires=range(num_qubits, num_qubits + num_document_qubits)) #measure the probability of each document index\n",
        "\n",
        "# Perform Grover's search\n",
        "probabilities = grover_search()\n",
        "if isinstance(probabilities, int): # Check if grover_search returned 0 due to insufficient document qubits.\n",
        "    most_likely_index = 0\n",
        "else:\n",
        "    most_likely_index = np.argmax(probabilities)\n",
        "print(\"Most likely index:\", most_likely_index)\n",
        "\n",
        "retrieved_document = corpus[most_likely_index]\n",
        "\n",
        "# VII. Answer Extraction (Basic)\n",
        "def extract_answer(document, question):\n",
        "    sentences = nltk.sent_tokenize(document)\n",
        "    #Remove this since Sentence Transformer encodes whole sentence\n",
        "    #question_embedding = create_document_embedding(preprocess(question), glove_embeddings, embedding_dim)\n",
        "    sentence_similarities = []\n",
        "    for sentence in sentences:\n",
        "        #Remove this since Sentence Transformer encodes whole sentence\n",
        "        #sentence_embedding = create_document_embedding(preprocess(sentence), glove_embeddings, embedding_dim)\n",
        "        similarity = cosine_similarity(model.encode(question).reshape(1, -1), model.encode(sentence).reshape(1, -1))[0][0]\n",
        "        sentence_similarities.append(similarity)\n",
        "    best_sentence_index = np.argmax(sentence_similarities)\n",
        "    return sentences[best_sentence_index]\n",
        "\n",
        "answer = extract_answer(retrieved_document, question)\n",
        "\n",
        "print(f\"Query: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560,
          "referenced_widgets": [
            "d8f956d88e3843f592f6092348e8f833",
            "c8b13715adab4572bdd3226a1476b317",
            "539bc31905b8444e97e50ded4da26868",
            "8a43a2fcb8a9492eaea0cb472816e8db",
            "41ed5295172049b29b52105b0218d0f4",
            "a88d80d2d53945439403a1805b6d75e9",
            "89f558840cbe4a8b9c64fdae330730df",
            "0e4c1718b1b34ff2a4812e5e7d820b18",
            "5743e4c5f5764e1cac72a3f9e727f6ab",
            "8e30d5b829e54de59110f7d00b6fe670",
            "20b8834708154f25a7b11cd8cfb7a555",
            "6c227b71a0b1468e9d670996d37a831f",
            "29b5e0274bcd4efbb3ca0c8014acdee6",
            "8b95dbf85fba4a9c85096ca2c574cd52",
            "7f64209ecc494914bc508c3fef892106",
            "cfe86a61ff66479295509e0b24904ffe",
            "ea3b8e279d0342e299c82d439badc1ae",
            "6c6d07a3ba344ebbb292ac55ccce5f00",
            "235858a5a3044b159b58fcd1a842222e",
            "618e7ffd662245639236c66d5b7f44cf",
            "869d01057c2042f29c5d09a0a95d49a0",
            "89f04a16e2754afdb0b604d0c14e6fce",
            "ed4bb090e74f4b5bb5ae336b32a65e80",
            "ada8fb1c11db4df6b275c68989893a11",
            "26f776e5cdf84e3494b16181f09ac04d",
            "7f99cc5b424a4102a19b2bdc44bfad8e",
            "d4b68b7fe2814d6784fa50d4c60ed8ec",
            "372a5a2303d940c8bd8d4fe47864d499",
            "52fbf79518da4a30a0a53f385a635682",
            "9f0d4acfd1d449559829bc2998d92adf",
            "15a17b5559a44bc2b16f332ebb1da7e0",
            "3ed5ba76f5784896b418c255e530dafb",
            "acdf6a06bf4847da924991a1978c1b02",
            "67609b6302e64a1b9a804b976b7265e8",
            "1ebfc303d9fa454590745984f8b2233d",
            "591ba499aa714df6bf50ec95fe2ae8fc",
            "3119757f136a47b0aa9c4537d95bb806",
            "96276a6ee68c48d7a8ea901c3dcae718",
            "2c625828432e4658a49b847cb4ad58dc",
            "52b27bca78654fc4b77a74fc4117448a",
            "20ac2ab2883b4dcd8dacd6550455942f",
            "aab8d19bda0c4e7e9f5d6bd975d0045e",
            "b1bb4eb2974f42bc9da21cd4d2317598",
            "a31d34408e124dcea724400442a11cd1",
            "718a3db278f84a49ad3d48cc2aa2df0b",
            "0ac09677e4134c2581a4d4982833fc2d",
            "d0dca2d6f17946608cd1f72666556cc8",
            "05e6aaa90c7d450787fd4346d64a560d",
            "2d36f8c5dca046c0ab449d8ec158d05c",
            "6f56a48e7ec046368c4963c1b21af15f",
            "a491fd70160c43d08051b827b90693c4",
            "5485c5b47f864040a2dcf2975acbe766",
            "13b0cad7b12342cfa6017eff874e0d03",
            "19d3372357834d4395ed5c4c3f526e7f",
            "5d9e7663bbda411facfd7c691e59b047",
            "abaae453fd274a409503c4dc042a6efe",
            "d0b41ebb2d3d48ff9b677c8cfcffc3c7",
            "0c52aba73e504a3c84c7548f456cc6c4",
            "28d9c4ea8534479d871eda1619133d4a",
            "15d50312162d48619bbbac63e21498b4",
            "f087f04fe25f4fa4ae1fb90e41891f62",
            "496f4ce792144e09b065d93ee0575dcf",
            "2fa0b1ffa1224436b1334423d3627ef8",
            "43898fb9042c4fb19fe929942000e3b5",
            "274bf61fbb77448a9b154e38b38307ee",
            "e2303c0f6bcb4ae0a69f0f17f2ca50f1",
            "d850c8e025f54ebdbb801b845cec7ecc",
            "a4d50c02c87e433eba1a95efc9a1ed70",
            "2db59d15d56a432a838d57299a81796c",
            "94c4f195ffff4198891545bc4641ab78",
            "c7399108bafe42f18881be5c62e76feb",
            "63ba34c34002418f8328dac4716a4798",
            "58bec4845af0430788ff0cb2f2747665",
            "cedeb1ebdc8c47c99414505599f631e8",
            "453efef71957494cb93fa76c1c8f51ef",
            "cf2c7ff83aaf4a51a8f2439f078ed3ef",
            "a4a0e57980344144a71d43d1ef757b98",
            "0f849efa6b584e94ad70ad0a7e3e4f35",
            "7a00e489f4cf4cb98b6591a558b18a8d",
            "fb48038b40324274996c2a43b699fedf",
            "b7143af2ec074f5cb817512c12298694",
            "8e6e6e0e37ff489f8c0ab2a7885c1aa3",
            "8fd83527392b4fd18ebb410fef50eb4f",
            "b268682c60934e0fa6e3add40b05c373",
            "b3adfedbdc9c4698954dab5cf03fca4f",
            "e8c1be01e37c430bb58f2fc8aac8548e",
            "c6aef7d431794ab0ad07fd09fd30f0e2",
            "12da6ce1e03e4b0f8c78e02efb14ca22",
            "0024df2189b442f0ab3a776b628c6474",
            "abc2e7ae8f94474e8a11ad91c9640681",
            "5bb8be20703a4d5f88f3ef0eda5b6d62",
            "eabeb311135a4ef39d03a18b052996e4",
            "d0e2c3f82f244bf78456f377f847c9ae",
            "40d370417a7a4ac7b91b84e38e921adc",
            "d00ecde2e4204c7ba31cfda5c39377ef",
            "ffbcdbb659444ee0bd80e53193343f44",
            "e661013d5d394294a47bbe09b5b7443a",
            "6106558b49664abbaf79adb80309a9b3",
            "d67dd6a753ec4fe1918335d43e210118",
            "ed34dff1d9744c10ad6488c25ddda184",
            "2933a814069a4e82821ca9e96bf09d66",
            "063f0eeccae74618b83bb0c17653482a",
            "edecef746ba941efb7e8255d2ff2da57",
            "df666f0d1d2347ba9a6b51cf699b9757",
            "ccc9284383524c2089d07c3d2ff0bc96",
            "d1bc6a5b5d044269adf495d822927086",
            "9dedc7ce78334ccdba653076b907af4e",
            "af5a967d26e14eaa89f84388e1c52d6d",
            "0a8f8f721858450bb0c1ffaa389a3c4d",
            "87e5124ed0ea45409d0f9c6db2cc0f32",
            "148479a91f144613a3c83b08aea0a7bd",
            "23ec4fb621d0477ca9346ae755316615",
            "89a72b0566864825b493222445957d49",
            "fa58767370314913a30340b5977c9736",
            "0c0f6bf94b254495a2923fa88a11b84a",
            "ff6135df1ac34a4bb90b24cae818352d",
            "cc4920cbca6d4b72aeeed22742fadae1",
            "6c1d928808884bb782ccb03ceb302548",
            "ef086b57b58946e1a653d22f07ce8c1d",
            "76d5660912f447888df3be0ff2babdda",
            "4de31091cd314b72a52503ed3b8338da"
          ]
        },
        "id": "7wErNqE9XqG6",
        "outputId": "7d8bfa06-1618-447c-ff48-7c5d5a3d7ad6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8f956d88e3843f592f6092348e8f833"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c227b71a0b1468e9d670996d37a831f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed4bb090e74f4b5bb5ae336b32a65e80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67609b6302e64a1b9a804b976b7265e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "718a3db278f84a49ad3d48cc2aa2df0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abaae453fd274a409503c4dc042a6efe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d850c8e025f54ebdbb801b845cec7ecc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f849efa6b584e94ad70ad0a7e3e4f35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0024df2189b442f0ab3a776b628c6474"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed34dff1d9744c10ad6488c25ddda184"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "148479a91f144613a3c83b08aea0a7bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Sentence Transformer model with dimension 768\n",
            "Enter your query: quantum\n",
            "Most likely index: 0\n",
            "Query: quantum\n",
            "Answer: The quick brown fox jumps over the lazy dog.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import requests, zipfile\n",
        "from shutil import copyfileobj\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# I. Setup and Downloads (NLTK and Sentence Transformers)\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "try:\n",
        "    word_tokenize(\"example text\")\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "\n",
        "# II. Load Sentence Transformer Model\n",
        "model = SentenceTransformer('all-mpnet-base-v2')\n",
        "embedding_dim = model.get_sentence_embedding_dimension() # Get Embedding Dimension\n",
        "print(f\"Loaded Sentence Transformer model with dimension {embedding_dim}\")\n",
        "\n",
        "# III. Larger Text Corpus and Preprocessing\n",
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog. This is a classic English pangram.\",\n",
        "    \"The cat sat on the mat, peacefully napping in the sun.\",\n",
        "    \"A dog is a loyal companion, offering unconditional love and support. Dogs are good pets.\",\n",
        "    \"The fox is a cunning animal, known for its cleverness and adaptability. Foxes are often found in forests.\",\n",
        "    \"Quantum computing holds the promise of revolutionizing various fields, including medicine and materials science.\",\n",
        "    \"Natural language processing (NLP) is a branch of artificial intelligence that deals with the interaction between computers and humans using natural language.\",\n",
        "    \"The Earth is the third planet from the Sun and the only known planet to harbor life.\",\n",
        "    \"Artificial intelligence (AI) is rapidly transforming industries and reshaping the way we live and work.\",\n",
        "    \"Climate change is a pressing global issue, requiring urgent action to mitigate its effects.\",\n",
        "    \"Renewable energy sources, such as solar and wind power, are becoming increasingly important in the transition to a sustainable future.\"\n",
        "]\n",
        "\n",
        "# Get user query from the command line\n",
        "question = input(\"Enter your query: \")\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w.lower() for w in tokens if w.isalpha()]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    return tokens\n",
        "\n",
        "processed_corpus = [preprocess(doc) for doc in corpus]\n",
        "processed_question = preprocess(question)\n",
        "\n",
        "# IV. Document and Query Embeddings (Using Sentence Transformers)\n",
        "corpus_embeddings = model.encode(corpus)  # Encode entire sentences\n",
        "question_embedding = model.encode(question)\n",
        "\n",
        "def normalize_vector(vector):\n",
        "    norm = np.linalg.norm(vector)\n",
        "    if norm == 0:\n",
        "        return vector\n",
        "    return vector / norm\n",
        "\n",
        "normalized_corpus_embeddings = [normalize_vector(embedding) for embedding in corpus_embeddings]\n",
        "normalized_question_embedding = normalize_vector(question_embedding)\n",
        "\n",
        "# V. Quantum Circuit Preparation, drop amplitude encoding\n",
        "num_documents = len(corpus)\n",
        "num_document_qubits = int(np.ceil(np.log2(num_documents)))\n",
        "dev = qml.device(\"default.qubit\", wires=num_document_qubits)\n",
        "\n",
        "\n",
        "# VI. Quantum Retrieval (Grover's Algorithm)\n",
        "\n",
        "# Calculate cosine similarities classically for oracle (simulated QRAM)\n",
        "similarities = [cosine_similarity(question_embedding.reshape(1,-1), corpus_embeddings[i].reshape(1,-1))[0][0] for i in range(num_documents)]\n",
        "\n",
        "#Set the threshold\n",
        "threshold = np.mean(similarities)\n",
        "\n",
        "def oracle(wires):\n",
        "    \"\"\"Marks states with similarity above the threshold.\"\"\"\n",
        "    for i in range(num_documents):\n",
        "        if similarities[i] >= threshold:\n",
        "            qml.FlipSign(wires=(wires[0],), n=1)\n",
        "\n",
        "#Grover operator to amplify good states\n",
        "\n",
        "def grover_diffusion_op(wires):\n",
        "    \"\"\"Grover diffusion operator.\"\"\"\n",
        "    for wire in wires:\n",
        "        qml.Hadamard(wires=wire)\n",
        "    for wire in wires:\n",
        "        qml.PauliX(wires=wire)\n",
        "    if len(wires) > 1:  # Apply CZ only if there are at least two qubits\n",
        "        qml.CZ(wires=[wires[0], wires[1]])\n",
        "    for wire in wires:\n",
        "        qml.PauliX(wires=wire)\n",
        "    for wire in wires:\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def grover_search():\n",
        "    \"\"\"Grover's algorithm implementation.\"\"\"\n",
        "    wires = range(num_document_qubits)\n",
        "    for wire in wires:\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "    # Number of Grover iterations\n",
        "    N = num_documents\n",
        "    num_iterations = int(np.floor(np.pi / 4 * np.sqrt(N)))\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        oracle(wires)\n",
        "        grover_diffusion_op(wires)\n",
        "\n",
        "    return qml.probs(wires=wires)\n",
        "\n",
        "# Perform Grover's search\n",
        "probabilities = grover_search()\n",
        "most_likely_index = np.argmax(probabilities)\n",
        "print(\"Most likely index:\", most_likely_index)\n",
        "\n",
        "retrieved_document = corpus[most_likely_index]\n",
        "\n",
        "# VII. Answer Extraction (Basic)\n",
        "def extract_answer(document, question):\n",
        "    sentences = nltk.sent_tokenize(document)\n",
        "    #Remove this since Sentence Transformer encodes whole sentence\n",
        "    #question_embedding = create_document_embedding(preprocess(question), glove_embeddings, embedding_dim)\n",
        "    sentence_similarities = []\n",
        "    for sentence in sentences:\n",
        "        #Remove this since Sentence Transformer encodes whole sentence\n",
        "        #sentence_embedding = create_document_embedding(preprocess(sentence), glove_embeddings, embedding_dim)\n",
        "        similarity = cosine_similarity(model.encode(question).reshape(1, -1), model.encode(sentence).reshape(1,-1))[0][0]\n",
        "        sentence_similarities.append(similarity)\n",
        "    best_sentence_index = np.argmax(sentence_similarities)\n",
        "    return sentences[best_sentence_index]\n",
        "\n",
        "answer = extract_answer(retrieved_document, question)\n",
        "\n",
        "print(f\"Query: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0_w6freYA-U",
        "outputId": "408fd74f-7722-4482-81d5-1a582a63e86a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Sentence Transformer model with dimension 768\n",
            "Enter your query: quantum\n",
            "Most likely index: 0\n",
            "Query: quantum\n",
            "Answer: The quick brown fox jumps over the lazy dog.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum Data Encoding:\n",
        "\n",
        "    Goal: Represent text data in a quantum format that captures semantic relationships and is amenable to quantum computation.\n",
        "\n",
        "    Approach: Variational Quantum Encoding (VQE).\n",
        "\n",
        "        Train a VQC to map classical text into a quantum Hilbert space.\n",
        "\n",
        "            Instead of starting from classical word embeddings, train from raw text using a quantum-classical hybrid approach.\n",
        "\n",
        "            Use a quantum loss function that promotes semantic similarity between documents with similar meanings. This could involve a quantum version of contrastive loss.\n",
        "\n",
        "Quantum Indexing:\n",
        "\n",
        "    Goal: Create a quantum data structure that allows for efficient retrieval of relevant documents.\n",
        "\n",
        "    Approach: Quantum Associative Memory (QuAM).\n",
        "\n",
        "          \n",
        "    *  Use a variation of QuAM that stores associations between query features and document features.\n",
        "\n",
        "        \n",
        "\n",
        "    IGNORE_WHEN_COPYING_START\n",
        "\n",
        "        Use code with caution.\n",
        "        IGNORE_WHEN_COPYING_END\n",
        "\n",
        "    Quantum Retrieval:\n",
        "\n",
        "        Goal: Use quantum algorithms to search the quantum index and retrieve relevant documents.\n",
        "\n",
        "        Approach: Quantum Amplitude Estimation (QAE) combined with Grover's Algorithm.\n",
        "\n",
        "    Quantum Answer Extraction:\n",
        "\n",
        "        Goal: Extract the most relevant information from the retrieved quantum documents to answer the query.\n",
        "\n",
        "        Approach: Quantum Attention Mechanisms with VQC.\n",
        "\n",
        "II. Implementation Details\n",
        "\n",
        "Since implementing the entire pipeline on real quantum hardware is currently infeasible, we'll focus on the most crucial components and simulate others.\n",
        "\n",
        "A. Variational Quantum Encoding (VQE)\n",
        "\n",
        "    Quantum Circuit Design:\n",
        "\n",
        "        Choose a suitable VQC architecture. Good choices include:\n",
        "\n",
        "            Hardware-Efficient Ansatz: Circuits designed to be easily implemented on specific quantum hardware.\n",
        "\n",
        "            Tree Tensor Network (TTN) Ansatz: Circuits inspired by tensor networks, which can efficiently represent complex quantum states.\n",
        "\n",
        "    Data Input:\n",
        "\n",
        "        Encode the raw text (or pre-processed tokens) into a feature vector that can be fed into the VQC.\n",
        "\n",
        "            Use techniques such as:\n",
        "\n",
        "                Character-level encoding.\n",
        "\n",
        "                Bag-of-words representation (with a limited vocabulary size).\n",
        "\n",
        "                TF-IDF vectors.\n",
        "\n",
        "    Quantum Loss Function:\n",
        "\n",
        "        Define a quantum loss function that guides the training of the VQC.\n",
        "\n",
        "            Examples:\n",
        "\n",
        "                Quantum Contrastive Loss: Similar documents should have quantum states with high fidelity (overlap), while dissimilar documents should have low fidelity.\n",
        "\n",
        "                      \n",
        "                L = (1 - y) * (1 - Fidelity(ψ1, ψ2)) + y * max(0, Fidelity(ψ1, ψ2) - margin)\n",
        "\n",
        "                    \n",
        "\n",
        "                IGNORE_WHEN_COPYING_START\n",
        "\n",
        "                Use code with caution.\n",
        "                IGNORE_WHEN_COPYING_END\n",
        "\n",
        "                where:\n",
        "\n",
        "                    y = 1 if the documents are similar, y = 0 if they are dissimilar.\n",
        "\n",
        "                    Fidelity(ψ1, ψ2) is the fidelity between the quantum states of the two documents.\n",
        "\n",
        "                    margin is a hyperparameter that controls the separation between similar and dissimilar documents.\n",
        "\n",
        "                Quantum Cross-Entropy Loss: If you have labeled data (e.g., document categories), you can use a quantum version of cross-entropy loss to train the VQC to classify documents.\n",
        "\n",
        "    Training Loop:\n",
        "\n",
        "        Use a hybrid quantum-classical optimization algorithm to train the VQC.\n",
        "\n",
        "            Examples:\n",
        "\n",
        "                Variational Quantum Eigensolver (VQE) with a classical optimizer like Adam or L-BFGS-B.\n",
        "\n",
        "                Parameter-shift rule for calculating gradients.\n",
        "\n",
        "    Output:\n",
        "\n",
        "        The trained VQC becomes the quantum feature map that encodes text into quantum states.\n",
        "\n",
        "B. Quantum Indexing (QuAM)\n",
        "\n",
        "    Feature Extraction:\n",
        "\n",
        "        Use the trained VQC to extract quantum features from each document.\n",
        "\n",
        "        The output quantum state of the VQC represents the features of the document.\n",
        "\n",
        "    Association Storage:\n",
        "\n",
        "        Store the associations between document indices and their quantum features in a QuAM.\n",
        "\n",
        "        This can be a theoretical step for now, as practical QuAM is not yet available.\n",
        "\n",
        "C. Quantum Retrieval (Grover's Algorithm + QAE)\n",
        "\n",
        "    Query Encoding:\n",
        "\n",
        "        Encode the query into a quantum state using the same VQC that was used to encode the documents.\n",
        "\n",
        "    Similarity Estimation:\n",
        "\n",
        "        Use Quantum Amplitude Estimation (QAE) to estimate the similarity between the query state and the document states stored in the QuAM.\n",
        "\n",
        "        QAE provides a quadratic speedup over classical methods for estimating amplitudes.\n",
        "\n",
        "    Grover's Algorithm:\n",
        "\n",
        "        Use Grover's algorithm to search the QuAM for documents with high similarity to the query.\n",
        "\n",
        "        The oracle for Grover's algorithm can be based on the amplitude estimates from QAE.\n",
        "\n",
        "D. Quantum Answer Extraction\n",
        "\n",
        "    Quantum Attention Mechanisms:\n",
        "\n",
        "        Implement quantum attention mechanisms to focus on the most relevant parts of the retrieved documents.\n",
        "\n",
        "            This involves using quantum circuits to calculate attention weights between the query and the document.\n",
        "\n",
        "    VQC for Answer Prediction:\n",
        "\n",
        "        Train another VQC to predict the answer to the query based on the attended document features.\n",
        "\n",
        "            This VQC can be trained to output a probability distribution over possible answers.\n",
        "      \n",
        "    IV. Optimization Strategies\n",
        "\n",
        "    Circuit Optimization:\n",
        "\n",
        "        Use circuit optimization techniques to reduce the number of gates and the circuit depth.\n",
        "\n",
        "            Examples:\n",
        "\n",
        "                Gate cancellation.\n",
        "\n",
        "                ZX calculus.\n",
        "\n",
        "                Quantum circuit compilation.\n",
        "\n",
        "    Noise Mitigation:\n",
        "\n",
        "        Implement error mitigation techniques to reduce the effects of quantum noise.\n",
        "\n",
        "            Examples:\n",
        "\n",
        "                Zero-noise extrapolation.\n",
        "\n",
        "                Probabilistic error cancellation.\n",
        "\n",
        "                Readout error mitigation.\n",
        "\n",
        "    Hardware-Aware Design:\n",
        "\n",
        "        Design the quantum circuits to match the specific architecture and connectivity of the available quantum hardware.\n",
        "\n",
        "            This can involve:\n",
        "\n",
        "                Qubit mapping.\n",
        "\n",
        "                Gate scheduling.\n",
        "\n",
        "                Pulse-level control.\n",
        "\n",
        "V. Remarks\n",
        "\n",
        "    Scalability:\n",
        "\n",
        "        Scalability is a major challenge for quantum RAG systems. The number of qubits required for amplitude encoding and quantum computations can grow exponentially with the size of the data.\n",
        "\n",
        "    Practicality:\n",
        "\n",
        "        Practical quantum RAG systems are still years away. Current quantum hardware is limited in terms of qubit count, coherence time, and gate fidelity.\n",
        "\n",
        "    Hybrid Approach:\n",
        "\n",
        "        In the near term, hybrid quantum-classical approaches are likely to be the most practical.\n",
        "\n",
        "            Use classical machine learning to pre-process data and prepare inputs for quantum algorithms.\n",
        "\n",
        "    Research Directions:\n",
        "\n",
        "        The field of quantum natural language processing (QNLP) is rapidly evolving. Stay up-to-date with the latest research and developments."
      ],
      "metadata": {
        "id": "ULK5QWaAYU5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import requests, zipfile\n",
        "from shutil import copyfileobj\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ---------------------- Section I: Setup ----------------------\n",
        "\n",
        "# 1. Download necessary NLTK resources\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "try:\n",
        "    word_tokenize(\"example text\")\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "\n",
        "# ---------------------- Section II: Load Resources and Preprocessing ----------------------\n",
        "\n",
        "# Load Text Corpus\n",
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog. This is a classic English pangram.\",\n",
        "    \"The cat sat on the mat, peacefully napping in the sun.\",\n",
        "    \"A dog is a loyal companion, offering unconditional love and support. Dogs are good pets.\",\n",
        "    \"The fox is a cunning animal, known for its cleverness and adaptability. Foxes are often found in forests.\",\n",
        "    \"Quantum computing holds the promise of revolutionizing various fields, including medicine and materials science.\",\n",
        "    \"Natural language processing (NLP) is a branch of artificial intelligence that deals with the interaction between computers and humans using natural language.\",\n",
        "    \"The Earth is the third planet from the Sun and the only known planet to harbor life.\",\n",
        "    \"Artificial intelligence (AI) is rapidly transforming industries and reshaping the way we live and work.\",\n",
        "    \"Climate change is a pressing global issue, requiring urgent action to mitigate its effects.\",\n",
        "    \"Renewable energy sources, such as solar and wind power, are becoming increasingly important in the transition to a sustainable future.\"\n",
        "]\n",
        "\n",
        "# Get user query\n",
        "question = input(\"Enter your query: \")\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w.lower() for w in tokens if w.isalpha()]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    return tokens\n",
        "\n",
        "processed_corpus = [preprocess(doc) for doc in corpus]\n",
        "processed_question = preprocess(question)\n",
        "\n",
        "# ---------------------- Section III: Quantum Data Encoding ----------------------\n",
        "num_qubits = 6  # Example, adjust based on needs\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "def create_feature_vector(text, vocab_size): #Dummy, just for demonstration\n",
        "    \"\"\"Create simple one-hot feature vector.\"\"\"\n",
        "    feature_vector = [0] * vocab_size\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "        feature_vector[hash(word) % vocab_size] = 1 #Arbitrary hashing\n",
        "    return feature_vector\n",
        "\n",
        "vocab_size = 100 #Set based on corpus analysis\n",
        "encoded_corpus_feature_vectors = [create_feature_vector(\" \".join(doc), vocab_size) for doc in processed_corpus] # Text to Numbers\n",
        "encoded_query_feature_vector = create_feature_vector(\" \".join(processed_question), vocab_size)\n",
        "\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def quantum_encoding_circuit(features, params): # Variational Quantum Circuit to be Trained\n",
        "    \"\"\"Example Quantum Circuit to map Features to Quantum State.\"\"\"\n",
        "    # Insert Circuit\n",
        "    return qml.state()\n",
        "\n",
        "# --- Simulated Training Section (This requires significant development) ---\n",
        "# Here should be training of quantum_encoding_circuit to generate appropriate quantum features based on the dataset\n",
        "# The data are \"encoded_corpus_feature_vectors\" and \"encoded_query_feature_vector\"\n",
        "# Training requires optimization of \"params\" and definition of appropriate \"quantum_loss\"\n",
        "\n",
        "params = np.random.rand(10)  # Example initialization, NEEDS TO BE ADJUSTED\n",
        "\n",
        "\n",
        "quantum_corpus_states = [quantum_encoding_circuit(feature, params) for feature in encoded_corpus_feature_vectors]  # Quantum States of Corpus\n",
        "quantum_query_state = quantum_encoding_circuit(encoded_query_feature_vector, params) # Quantum State of Query\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------- Section IV: Quantum Retrieval  ----------------------\n",
        "num_document_qubits = int(np.ceil(np.log2(len(corpus))))\n",
        "dev_grover = qml.device(\"default.qubit\", wires=num_document_qubits) # Quantum Device for Grover's alg\n",
        "\n",
        "# Manually assign the number of wires\n",
        "num_wires = dev_grover.num_wires  = num_document_qubits\n",
        "\n",
        "# Simulated Quantum Similarity Calculation (Replace with QAE later)\n",
        "def quantum_state_similarity(state1, state2): #Simulated Quantum Similarity\n",
        "  similarity = cosine_similarity(np.real(state1).reshape(1,-1), np.real(state2).reshape(1,-1))[0][0]\n",
        "  return similarity\n",
        "\n",
        "\n",
        "@qml.qnode(dev_grover)\n",
        "def grover_search(quantum_states, quantum_query):\n",
        "\n",
        "  #Oracle Phase\n",
        "  def oracle(wires):\n",
        "        max_sim = max([quantum_state_similarity(quantum_query, quantum_states[i]) for i in range(len(quantum_states))])\n",
        "        similarities = [quantum_state_similarity(quantum_query, quantum_states[i]) for i in range(len(quantum_states))]\n",
        "        for i in range(len(quantum_states)):\n",
        "            if similarities[i] >= max_sim:\n",
        "                qml.FlipSign(wires=wires, n = 1)\n",
        "\n",
        "  def grover_diffusion_op(wires):\n",
        "    \"\"\"Grover diffusion operator.\"\"\"\n",
        "    for wire in wires:\n",
        "        qml.Hadamard(wires=wire)\n",
        "    for wire in wires:\n",
        "        qml.PauliX(wires=wire)\n",
        "    if len(wires) > 1:  # Apply CZ only if there are at least two qubits\n",
        "        qml.CZ(wires=[wires[0], wires[1]])\n",
        "    for wire in wires:\n",
        "        qml.PauliX(wires=wire)\n",
        "    for wire in wires:\n",
        "        qml.Hadamard(wires=wire)\n",
        "\n",
        "  # Apply Hadamards\n",
        "  wires = range(num_wires)\n",
        "  for wire in wires:\n",
        "    qml.Hadamard(wires=wire)\n",
        "\n",
        "    # Number of Grover iterations\n",
        "  N = len(quantum_states)\n",
        "  num_iterations = int(np.floor(np.pi / 4 * np.sqrt(N)))\n",
        "   #Run Grover's\n",
        "  for _ in range(num_iterations):\n",
        "      oracle(wires)\n",
        "      grover_diffusion_op(wires)\n",
        "\n",
        "  return qml.probs(wires=wires) # Output\n",
        "print(\"grover probs\")\n",
        "probabilities = grover_search(quantum_corpus_states,quantum_query_state)  # Run Grover and get Probabilities\n",
        "print(probabilities)\n",
        "\n",
        "\n",
        "most_likely_index = np.argmax(probabilities)  # Index of most likely document.\n",
        "\n",
        "# ---------------------- Section V: Quantum Answer Extraction (Simulated) ----------------------\n",
        "# --- Replace with Learned Quantum Answer Extraction Section ---\n",
        "def extract_answer(document, question):  # Basic answer extraction (as before)\n",
        "    sentences = nltk.sent_tokenize(document)\n",
        "    #Remove this since Sentence Transformer encodes whole sentence\n",
        "    #question_embedding = create_document_embedding(preprocess(question), glove_embeddings, embedding_dim)\n",
        "    sentence_similarities = []\n",
        "    model = SentenceTransformer('all-mpnet-base-v2')\n",
        "    for sentence in sentences:\n",
        "        #Remove this since Sentence Transformer encodes whole sentence\n",
        "        #sentence_embedding = create_document_embedding(preprocess(sentence), glove_embeddings, embedding_dim)\n",
        "        similarity = cosine_similarity(model.encode(question).reshape(1, -1), model.encode(sentence).reshape(1,-1))[0][0]\n",
        "        sentence_similarities.append(similarity)\n",
        "    best_sentence_index = np.argmax(sentence_similarities)\n",
        "    return sentences[best_sentence_index]\n",
        "\n",
        "\n",
        "retrieved_document = corpus[most_likely_index]\n",
        "answer = extract_answer(retrieved_document, question)\n",
        "\n",
        "print(f\"Query: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmUEAmGVYY7P",
        "outputId": "0296ef52-6f3f-4abf-87ec-3574666fea71"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query: quantum\n",
            "grover probs\n",
            "[0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
            " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
            "Query: quantum\n",
            "Answer: The quick brown fox jumps over the lazy dog.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import requests, zipfile\n",
        "from shutil import copyfileobj\n",
        "import torch\n",
        "\n",
        "# ---------------------- Section I: Setup ----------------------\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "try:\n",
        "    word_tokenize(\"example text\")\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "# ---------------------- Section II: Load Resources and Preprocessing ----------------------\n",
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"The cat sat on the mat.\",\n",
        "    \"A dog is a loyal companion.\",\n",
        "    \"The fox is a cunning animal.\",\n",
        "    \"Quantum computing is promising.\",\n",
        "    \"NLP is a branch of AI.\",\n",
        "    \"Earth is the third planet.\",\n",
        "    \"AI is transforming industries.\",\n",
        "    \"Climate change is a global issue.\",\n",
        "    \"Renewable energy is important.\"\n",
        "]\n",
        "question = input(\"Enter your query: \")\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w.lower() for w in tokens if w.isalpha()]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    return tokens\n",
        "\n",
        "processed_corpus = [preprocess(doc) for doc in corpus]\n",
        "processed_question = preprocess(question)\n",
        "\n",
        "# ---------------------- Section III: Quantum Data Encoding & Training ----------------------\n",
        "num_qubits = 2  # Limited Qubits for Simplicity\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "def create_feature_vector(text, vocab_size):\n",
        "    \"\"\"Improved: Create feature vector counting word occurrences.\"\"\"\n",
        "    feature_vector = np.zeros(vocab_size)\n",
        "    tokens = preprocess(text)  # Use preprocess here\n",
        "    for token in tokens:\n",
        "        feature_vector[hash(token) % vocab_size] += 1\n",
        "    return feature_vector\n",
        "\n",
        "vocab_size = 20  # Increased vocab size to capture more variance\n",
        "\n",
        "# Create feature vectors for corpus and query\n",
        "encoded_corpus_feature_vectors = [create_feature_vector(doc, vocab_size) for doc in corpus]\n",
        "encoded_query_feature_vector = create_feature_vector(question, vocab_size)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_encoding_circuit(features, params):\n",
        "    \"\"\"Variational Quantum Circuit to map Features to Quantum State.\"\"\"\n",
        "    qml.Hadamard(wires=0)\n",
        "    qml.RY(params[0], wires=0)\n",
        "    qml.CNOT(wires=[0, 1])  # Entanglement\n",
        "    qml.RY(params[1], wires=1)\n",
        "    # Implement feature loading\n",
        "    for i in range(len(features)):\n",
        "        qml.RY(features[i] * params[i+2], wires=0) # data-reuploading\n",
        "    return qml.probs(wires=[0,1])\n",
        "\n",
        "# --- Simulated Training ---\n",
        "num_params = vocab_size + 2 # num weights + 2 variational parameters\n",
        "\n",
        "# 2 is for the number of variational params,\n",
        "params = torch.tensor(np.random.rand(num_params), requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.Adam([params], lr=0.1) #Torch Optimizer\n",
        "num_steps = 100 #Reduced training steps for simplicity.\n",
        "\n",
        "def quantum_loss(params, feature_vector, target):\n",
        "    \"\"\"Quantum loss function (example: Mean Squared Error).\"\"\"\n",
        "    probs = quantum_encoding_circuit(feature_vector, params)\n",
        "    loss = torch.sum((probs - torch.tensor(target)) ** 2)  # MSE\n",
        "    return loss\n",
        "\n",
        "#Emulate the Training\n",
        "# Training Data must be manually crafted\n",
        "# Given the number of examples I will target specific circuit outputs to correspond to relevance.\n",
        "\n",
        "emulated_training_data = [\n",
        "    (encoded_corpus_feature_vectors[0], [0.2, 0.2, 0.3, 0.3]),  # Relevant\n",
        "    (encoded_corpus_feature_vectors[1], [0.25, 0.25, 0.25, 0.25]), # Not relevant\n",
        "    (encoded_corpus_feature_vectors[2], [0.3, 0.3, 0.2, 0.2]),    # Relevant\n",
        "    (encoded_corpus_feature_vectors[3], [0.25, 0.25, 0.25, 0.25]), # Not Relevant\n",
        "    (encoded_corpus_feature_vectors[4], [0.4, 0.1, 0.4, 0.1]),  # Relevant\n",
        "    (encoded_corpus_feature_vectors[5], [0.25, 0.25, 0.25, 0.25]), # Not relevant\n",
        "    (encoded_corpus_feature_vectors[6], [0.1, 0.4, 0.1, 0.4]), # Relevant\n",
        "    (encoded_corpus_feature_vectors[7], [0.25, 0.25, 0.25, 0.25]), # Not relevant\n",
        "    (encoded_corpus_feature_vectors[8], [0.2, 0.3, 0.2, 0.3]),    # Relevant\n",
        "    (encoded_corpus_feature_vectors[9], [0.25, 0.25, 0.25, 0.25]), # Not Relevant\n",
        "\n",
        "]\n",
        "\n",
        "for step in range(num_steps):\n",
        "    for feature_vector, target in emulated_training_data:\n",
        "        optimizer.zero_grad() #Zero the gradient\n",
        "        loss = quantum_loss(params, feature_vector, target) # Calculate Loss\n",
        "        loss.backward() # Calculate Gradients\n",
        "        optimizer.step() #Update Parameters\n",
        "\n",
        "    if (step + 1) % 10 == 0:\n",
        "        print(f\"Step {step+1}: Cost = {loss.item():.4f}\")\n",
        "\n",
        "quantum_corpus_states = [quantum_encoding_circuit(feature, params).detach().numpy() for feature in encoded_corpus_feature_vectors] # Quantum States of Corpus\n",
        "quantum_query_state = quantum_encoding_circuit(encoded_query_feature_vector, params).detach().numpy() # Quantum State of Query\n",
        "\n",
        "# ---------------------- Section IV: Quantum Retrieval ----------------------\n",
        "def state_overlap(state1, state2):\n",
        "    \"\"\"Calculates the overlap (similarity) between two quantum states.\"\"\"\n",
        "    overlap = np.abs(np.dot(np.conj(state1), state2))**2\n",
        "    return overlap\n",
        "\n",
        "# Calculate overlap between query state and corpus states\n",
        "overlaps = [state_overlap(quantum_query_state, state) for state in quantum_corpus_states]\n",
        "\n",
        "# Select the most relevant document\n",
        "most_likely_index = np.argmax(overlaps)\n",
        "\n",
        "retrieved_document = corpus[most_likely_index]\n",
        "\n",
        "print(f\"Query: {question}\")\n",
        "print(f\"Answer: {retrieved_document}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPXFCryBZrkb",
        "outputId": "f1c3a2bc-ea6b-41fc-d72b-05eb6b24b197"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query: quantum\n",
            "Step 10: Cost = 0.0028\n",
            "Step 20: Cost = 0.0120\n",
            "Step 30: Cost = 0.0116\n",
            "Step 40: Cost = 0.0315\n",
            "Step 50: Cost = 0.0405\n",
            "Step 60: Cost = 0.0338\n",
            "Step 70: Cost = 0.0298\n",
            "Step 80: Cost = 0.0281\n",
            "Step 90: Cost = 0.0275\n",
            "Step 100: Cost = 0.0275\n",
            "Query: quantum\n",
            "Answer: The cat sat on the mat.\n"
          ]
        }
      ]
    }
  ]
}